{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://github.com/jtobelem-simplon/prepa-dp100/blob/master/images/top.png?raw=true'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration (à lancer avant tous les notebooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.8.5'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version de python\n",
    "import platform\n",
    "platform.python_version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# packages in environment at /home/lab/anaconda3/envs/azure:\r\n",
      "#\r\n",
      "# Name                    Version                   Build  Channel\r\n",
      "_libgcc_mutex             0.1                        main  \r\n",
      "adal                      1.2.3                    pypi_0    pypi\r\n",
      "applicationinsights       0.11.9                   pypi_0    pypi\r\n",
      "argon2-cffi               20.1.0           py38h7b6447c_1  \r\n",
      "attrs                     20.1.0                     py_0  \r\n",
      "azure-common              1.1.25                   pypi_0    pypi\r\n",
      "azure-core                1.5.0                    pypi_0    pypi\r\n",
      "azure-graphrbac           0.61.1                   pypi_0    pypi\r\n",
      "azure-identity            1.2.0                    pypi_0    pypi\r\n",
      "azure-mgmt-authorization  0.60.0                   pypi_0    pypi\r\n",
      "azure-mgmt-containerregistry 2.8.0                    pypi_0    pypi\r\n",
      "azure-mgmt-keyvault       2.2.0                    pypi_0    pypi\r\n",
      "azure-mgmt-network        10.2.0                   pypi_0    pypi\r\n",
      "azure-mgmt-resource       9.0.0                    pypi_0    pypi\r\n",
      "azure-mgmt-storage        10.0.0                   pypi_0    pypi\r\n",
      "azureml-automl-core       1.8.0                    pypi_0    pypi\r\n",
      "azureml-contrib-pipeline-steps 1.6.0                    pypi_0    pypi\r\n",
      "azureml-core              1.8.0                    pypi_0    pypi\r\n",
      "azureml-dataprep          1.8.3                    pypi_0    pypi\r\n",
      "azureml-dataprep-native   14.2.1                   pypi_0    pypi\r\n",
      "azureml-explain-model     1.8.0                    pypi_0    pypi\r\n",
      "azureml-interpret         1.8.0                    pypi_0    pypi\r\n",
      "azureml-pipeline          1.8.0                    pypi_0    pypi\r\n",
      "azureml-pipeline-core     1.8.0                    pypi_0    pypi\r\n",
      "azureml-pipeline-steps    1.8.0                    pypi_0    pypi\r\n",
      "azureml-sdk               1.8.0                    pypi_0    pypi\r\n",
      "azureml-telemetry         1.8.0                    pypi_0    pypi\r\n",
      "azureml-train             1.8.0                    pypi_0    pypi\r\n",
      "azureml-train-automl-client 1.8.0                    pypi_0    pypi\r\n",
      "azureml-train-core        1.8.0                    pypi_0    pypi\r\n",
      "azureml-train-restclients-hyperdrive 1.8.0                    pypi_0    pypi\r\n",
      "azureml-widgets           1.6.0                    pypi_0    pypi\r\n",
      "backcall                  0.2.0                      py_0  \r\n",
      "backports-tempfile        1.0                      pypi_0    pypi\r\n",
      "backports-weakref         1.0.post1                pypi_0    pypi\r\n",
      "blas                      1.0                         mkl  \r\n",
      "bleach                    3.1.5                      py_0  \r\n",
      "ca-certificates           2020.7.22                     0  \r\n",
      "certifi                   2020.6.20                py38_0  \r\n",
      "cffi                      1.14.0                   pypi_0    pypi\r\n",
      "chardet                   3.0.4                    pypi_0    pypi\r\n",
      "cloudpickle               1.4.1                    pypi_0    pypi\r\n",
      "contextlib2               0.6.0.post1              pypi_0    pypi\r\n",
      "cryptography              2.9.2                    pypi_0    pypi\r\n",
      "cycler                    0.10.0                   py38_0  \r\n",
      "dbus                      1.13.16              hb2f20db_0  \r\n",
      "decorator                 4.4.2                      py_0  \r\n",
      "defusedxml                0.6.0                      py_0  \r\n",
      "distro                    1.5.0                    pypi_0    pypi\r\n",
      "docker                    4.2.0                    pypi_0    pypi\r\n",
      "dotnetcore2               2.1.14                   pypi_0    pypi\r\n",
      "entrypoints               0.3                      py38_0  \r\n",
      "expat                     2.2.9                he6710b0_2  \r\n",
      "flake8                    3.7.9                    pypi_0    pypi\r\n",
      "fontconfig                2.13.0               h9420a91_0  \r\n",
      "freetype                  2.10.2               h5ab3b9f_0  \r\n",
      "fusepy                    3.0.1                    pypi_0    pypi\r\n",
      "glib                      2.65.0               h3eb4bd4_0  \r\n",
      "gst-plugins-base          1.14.0               hbbd80ab_1  \r\n",
      "gstreamer                 1.14.0               hb31296c_0  \r\n",
      "icu                       58.2                 he6710b0_3  \r\n",
      "idna                      2.9                      pypi_0    pypi\r\n",
      "importlib-metadata        1.7.0                    py38_0  \r\n",
      "importlib_metadata        1.7.0                         0  \r\n",
      "intel-openmp              2020.2                      254  \r\n",
      "interpret-community       0.12.1                   pypi_0    pypi\r\n",
      "interpret-core            0.1.21                   pypi_0    pypi\r\n",
      "ipykernel                 5.3.4            py38h5ca1d4c_0  \r\n",
      "ipython                   7.18.1           py38h5ca1d4c_0  \r\n",
      "ipython_genutils          0.2.0                    py38_0  \r\n",
      "ipywidgets                7.5.1                      py_0  \r\n",
      "isodate                   0.6.0                    pypi_0    pypi\r\n",
      "jedi                      0.17.0           py38h32f6830_0    conda-forge\r\n",
      "jeepney                   0.4.3                    pypi_0    pypi\r\n",
      "jinja2                    2.11.2                     py_0  \r\n",
      "jmespath                  0.10.0                   pypi_0    pypi\r\n",
      "joblib                    0.15.1                   pypi_0    pypi\r\n",
      "jpeg                      9b                   h024ee3a_2  \r\n",
      "jsonpickle                1.4.1                    pypi_0    pypi\r\n",
      "jsonschema                3.2.0                    py38_0  \r\n",
      "jupyter                   1.0.0                    py38_7  \r\n",
      "jupyter_client            6.1.6                      py_0  \r\n",
      "jupyter_console           6.2.0                      py_0  \r\n",
      "jupyter_contrib_core      0.3.3                      py_2    conda-forge\r\n",
      "jupyter_contrib_nbextensions 0.5.1                    py38_0    conda-forge\r\n",
      "jupyter_core              4.6.3                    py38_0  \r\n",
      "jupyter_highlight_selected_word 0.2.0                 py38_1000    conda-forge\r\n",
      "jupyter_latex_envs        1.4.6                 py38_1000    conda-forge\r\n",
      "jupyter_nbextensions_configurator 0.4.1                    py38_0    conda-forge\r\n",
      "kiwisolver                1.2.0            py38hfd86e86_0  \r\n",
      "ld_impl_linux-64          2.33.1               h53a641e_7  \r\n",
      "libedit                   3.1.20191231         h14c3975_1  \r\n",
      "libffi                    3.3                  he6710b0_2  \r\n",
      "libgcc-ng                 9.1.0                hdf63c60_0  \r\n",
      "libgfortran-ng            7.3.0                hdf63c60_0  \r\n",
      "libpng                    1.6.37               hbc83047_0  \r\n",
      "libsodium                 1.0.18               h7b6447c_0  \r\n",
      "libstdcxx-ng              9.1.0                hdf63c60_0  \r\n",
      "libuuid                   1.0.3                h1bed415_2  \r\n",
      "libxcb                    1.14                 h7b6447c_0  \r\n",
      "libxml2                   2.9.10               he19cac6_1  \r\n",
      "libxslt                   1.1.34               hc22bd24_0  \r\n",
      "lxml                      4.5.2            py38hefd8a0e_0  \r\n",
      "markupsafe                1.1.1            py38h7b6447c_0  \r\n",
      "matplotlib                3.1.3                    py38_0  \r\n",
      "matplotlib-base           3.1.3            py38hef1b27d_0  \r\n",
      "mccabe                    0.6.1                    pypi_0    pypi\r\n",
      "mistune                   0.8.4           py38h7b6447c_1000  \r\n",
      "mkl                       2020.2                      256  \r\n",
      "mkl-service               2.3.0            py38he904b0f_0  \r\n",
      "mkl_fft                   1.1.0            py38h23d657b_0  \r\n",
      "mkl_random                1.1.1            py38h0573a6f_0  \r\n",
      "msal                      1.3.0                    pypi_0    pypi\r\n",
      "msal-extensions           0.1.3                    pypi_0    pypi\r\n",
      "msrest                    0.6.14                   pypi_0    pypi\r\n",
      "msrestazure               0.6.3                    pypi_0    pypi\r\n",
      "nbconvert                 5.6.1                    py38_0  \r\n",
      "nbformat                  5.0.7                      py_0  \r\n",
      "ncurses                   6.2                  he6710b0_1  \r\n",
      "ndg-httpsclient           0.5.1                    pypi_0    pypi\r\n",
      "notebook                  6.1.1                    py38_0  \r\n",
      "numpy                     1.18.4                   pypi_0    pypi\r\n",
      "numpy-base                1.19.1           py38hfa32c7d_0  \r\n",
      "oauthlib                  3.1.0                    pypi_0    pypi\r\n",
      "onnx                      1.7.0                    pypi_0    pypi\r\n",
      "onnxruntime               1.3.0                    pypi_0    pypi\r\n",
      "openssl                   1.1.1g               h7b6447c_0  \r\n",
      "packaging                 20.4                       py_0  \r\n",
      "pandas                    1.0.4                    pypi_0    pypi\r\n",
      "pandoc                    2.10.1                        0  \r\n",
      "pandocfilters             1.4.2                    py38_1  \r\n",
      "parso                     0.8.0                      py_0  \r\n",
      "pathspec                  0.8.0                    pypi_0    pypi\r\n",
      "pcre                      8.44                 he6710b0_0  \r\n",
      "pexpect                   4.8.0                    py38_0  \r\n",
      "pickleshare               0.7.5                 py38_1000  \r\n",
      "pip                       20.0.2                   py38_3  \r\n",
      "portalocker               1.7.0                    pypi_0    pypi\r\n",
      "prometheus_client         0.8.0                      py_0  \r\n",
      "prompt-toolkit            3.0.7                      py_0  \r\n",
      "prompt_toolkit            3.0.7                         0  \r\n",
      "protobuf                  3.12.2                   pypi_0    pypi\r\n",
      "psutil                    5.7.2            py38h7b6447c_0    anaconda\r\n",
      "ptyprocess                0.6.0                    py38_0  \r\n",
      "pyasn1                    0.4.8                    pypi_0    pypi\r\n",
      "pycodestyle               2.5.0                    pypi_0    pypi\r\n",
      "pycparser                 2.20                       py_2  \r\n",
      "pyflakes                  2.1.1                    pypi_0    pypi\r\n",
      "pygments                  2.6.1                      py_0  \r\n",
      "pyjwt                     1.7.1                    pypi_0    pypi\r\n",
      "pyopenssl                 19.1.0                   pypi_0    pypi\r\n",
      "pyparsing                 2.4.7                      py_0  \r\n",
      "pyqt                      5.9.2            py38h05f1152_4  \r\n",
      "pyrsistent                0.16.0           py38h7b6447c_0  \r\n",
      "python                    3.8.5                h7579374_1  \r\n",
      "python-dateutil           2.8.1                      py_0  \r\n",
      "python_abi                3.8                      1_cp38    conda-forge\r\n",
      "pytz                      2020.1                     py_0  \r\n",
      "pyyaml                    5.3.1            py38h7b6447c_1  \r\n",
      "pyzmq                     19.0.1           py38he6710b0_1  \r\n",
      "qt                        5.9.7                h5867ecd_1  \r\n",
      "qtconsole                 4.7.6                      py_0  \r\n",
      "qtpy                      1.9.0                      py_0  \r\n",
      "readline                  8.0                  h7b6447c_0  \r\n",
      "requests                  2.23.0                   pypi_0    pypi\r\n",
      "requests-oauthlib         1.3.0                    pypi_0    pypi\r\n",
      "ruamel-yaml               0.16.10                  pypi_0    pypi\r\n",
      "ruamel-yaml-clib          0.2.0                    pypi_0    pypi\r\n",
      "scikit-learn              0.23.1                   pypi_0    pypi\r\n",
      "scipy                     1.4.1                    pypi_0    pypi\r\n",
      "seaborn                   0.11.0                   pypi_0    pypi\r\n",
      "secretstorage             3.1.2                    pypi_0    pypi\r\n",
      "send2trash                1.5.0                    py38_0  \r\n",
      "setuptools                49.6.0                   py38_0  \r\n",
      "shap                      0.34.0                   pypi_0    pypi\r\n",
      "sip                       4.19.13          py38he6710b0_0  \r\n",
      "six                       1.15.0                     py_0  \r\n",
      "sqlite                    3.33.0               h62c20be_0  \r\n",
      "terminado                 0.8.3                    py38_0  \r\n",
      "testpath                  0.4.4                      py_0  \r\n",
      "threadpoolctl             2.1.0                    pypi_0    pypi\r\n",
      "tk                        8.6.10               hbc83047_0  \r\n",
      "tornado                   6.0.4            py38h7b6447c_1  \r\n",
      "tqdm                      4.46.0                   pypi_0    pypi\r\n",
      "traitlets                 4.3.3                    py38_0  \r\n",
      "typing-extensions         3.7.4.2                  pypi_0    pypi\r\n",
      "urllib3                   1.25.9                   pypi_0    pypi\r\n",
      "wcwidth                   0.2.5                      py_0  \r\n",
      "webencodings              0.5.1                    py38_1  \r\n",
      "websocket-client          0.57.0                   pypi_0    pypi\r\n",
      "wheel                     0.35.1                     py_0  \r\n",
      "widgetsnbextension        3.5.1                    py38_0  \r\n",
      "xz                        5.2.5                h7b6447c_0  \r\n",
      "yaml                      0.2.5                h7b6447c_0  \r\n",
      "zeromq                    4.3.2                he6710b0_2  \r\n",
      "zipp                      3.1.0                      py_0  \r\n",
      "zlib                      1.2.11               h7b6447c_3  \r\n"
     ]
    }
   ],
   "source": [
    "# la liste des packages installés\n",
    "!conda list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to use Azure ML 1.8.0\n"
     ]
    }
   ],
   "source": [
    "# version de la SDK azureml\n",
    "import azureml.core\n",
    "print(\"Ready to use Azure ML\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si le notebook est executé en dehors d'Azure, il faut télécharger le fichier config.json depuis le portail https://portal.azure.com/, et le mettre dans le workspace qui contient le notebook.\n",
    "\n",
    "Si le notebook est exécuté directement depuis le workspace Azure, le fichier de config devrait déjà être là."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jt-dp100 loaded\n"
     ]
    }
   ],
   "source": [
    "# connexion au workspace\n",
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print(ws.name, \"loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création du script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'titanic-training/titanic.csv'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, shutil\n",
    "\n",
    "# Create a folder for the experiment files\n",
    "training_folder = 'titanic-training'\n",
    "os.makedirs(training_folder, exist_ok=True)\n",
    "\n",
    "# Copy the data file into the experiment folder\n",
    "shutil.copy('data/titanic/train.csv', os.path.join(training_folder, \"titanic.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing titanic-training/titanic_training.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $training_folder/titanic_training.py\n",
    "from azureml.core import Run\n",
    "import joblib\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Get the experiment run context\n",
    "run = Run.get_context()\n",
    "\n",
    "train_data = pd.read_csv(\"titanic.csv\")\n",
    "\n",
    "features = [\"Age\",\"Pclass\",\"SibSp\", \"Parch\", \"Fare\",\"Sex\", \"Embarked\"]\n",
    "\n",
    "X = pd.get_dummies(train_data[features])\n",
    "y = train_data[\"Survived\"]\n",
    "\n",
    "# missing values\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "imputed_X = pd.DataFrame(imputer.fit_transform(X))\n",
    "imputed_X.columns = X.columns\n",
    "imputed_X[[\"Age\",\"Pclass\",\"SibSp\", \"Parch\", \"Fare\"]] = imputed_X[[\"Age\",\"Pclass\",\"SibSp\", \"Parch\", \"Fare\"]].astype('int')\n",
    "\n",
    "\n",
    "# Break off validation set from training data\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(imputed_X, y, train_size=0.8, test_size=0.2,\n",
    "                                                                random_state=0)\n",
    "\n",
    "# model\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# score\n",
    "predictions = model.predict(X_valid)\n",
    "\n",
    "mae = mean_absolute_error(predictions.astype('int'), y_valid)\n",
    "acc = accuracy_score(y_valid, predictions.astype('int'))\n",
    "print(\"mae : {}, accuracy : {}\".format(mae, acc))\n",
    "run.log('mae', mae)\n",
    "run.log('acc',acc)\n",
    "\n",
    "# Save the trained model in the outputs folder\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "joblib.dump(value=model, filename='outputs/titanic_model.pkl')\n",
    "\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrainement d'un modèle sur la machine locale\n",
    "\n",
    "[tutoriel microsoft : partie 1](https://docs.microsoft.com/en-us/azure/machine-learning/tutorial-train-models-with-aml)\n",
    "\n",
    "[tutoriel microsoft : partie 2](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-train-ml-models)\n",
    "\n",
    "- [experiment dans la SDK](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.experiment.experiment?view=azure-ml-py)\n",
    "\n",
    "- [estimator dans la SDK](https://docs.microsoft.com/en-us/python/api/azureml-train-core/azureml.train.estimator.estimator?view=azure-ml-py)\n",
    "\n",
    "NB : en cas d'erreur avec docker, https://askubuntu.com/questions/477551/how-can-i-use-docker-without-sudo\n",
    "\n",
    "`sudo usermod -aG docker $USER`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: titanic-training-experiment_1600098729_8053c661\n",
      "Web View: https://ml.azure.com/experiments/titanic-training-experiment/runs/titanic-training-experiment_1600098729_8053c661?wsid=/subscriptions/9114a63e-9210-4e32-97ca-b7d9e8ac403d/resourcegroups/jt-dp100-ressources/workspaces/jt-dp100\n",
      "\n",
      "Streaming azureml-logs/70_driver_log.txt\n",
      "========================================\n",
      "\n",
      "[2020-09-14T15:52:17.076248] Entering context manager injector.\n",
      "[context_manager_injector.py] Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError'], invocation=['titanic_training.py'])\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 10\n",
      "Entering Run History Context Manager.\n",
      "Current directory:  /azureml-run\n",
      "Preparing to call script [ titanic_training.py ] with arguments: []\n",
      "After variable expansion, calling script [ titanic_training.py ] with arguments: []\n",
      "\n",
      "Script type = None\n",
      "mae : 0.1787709497206704, accuracy : 0.8212290502793296\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 10\n",
      "\n",
      "\n",
      "The experiment completed successfully. Finalizing run...\n",
      "Logging experiment finalizing status in history service.\n",
      "[2020-09-14T15:52:26.937967] TimeoutHandler __init__\n",
      "[2020-09-14T15:52:26.938024] TimeoutHandler __enter__\n",
      "Cleaning up all outstanding Run operations, waiting 300.0 seconds\n",
      "2 items cleaning up...\n",
      "Cleanup took 0.6417102813720703 seconds\n",
      "[2020-09-14T15:52:28.708317] TimeoutHandler __exit__\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: titanic-training-experiment_1600098729_8053c661\n",
      "Web View: https://ml.azure.com/experiments/titanic-training-experiment/runs/titanic-training-experiment_1600098729_8053c661?wsid=/subscriptions/9114a63e-9210-4e32-97ca-b7d9e8ac403d/resourcegroups/jt-dp100-ressources/workspaces/jt-dp100\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'titanic-training-experiment_1600098729_8053c661',\n",
       " 'target': 'local',\n",
       " 'status': 'Completed',\n",
       " 'startTimeUtc': '2020-09-14T15:52:16.002022Z',\n",
       " 'endTimeUtc': '2020-09-14T15:52:35.119591Z',\n",
       " 'properties': {'_azureml.ComputeTargetType': 'local',\n",
       "  'ContentSnapshotId': 'a74336a6-a407-4052-bf84-44ec5799e468',\n",
       "  'azureml.git.repository_uri': 'https://github.com/jtobelem-simplon/prepa-dp100.git',\n",
       "  'mlflow.source.git.repoURL': 'https://github.com/jtobelem-simplon/prepa-dp100.git',\n",
       "  'azureml.git.branch': 'master',\n",
       "  'mlflow.source.git.branch': 'master',\n",
       "  'azureml.git.commit': '2d45093ddce878c37e597457953a961b3ad2cf28',\n",
       "  'mlflow.source.git.commit': '2d45093ddce878c37e597457953a961b3ad2cf28',\n",
       "  'azureml.git.dirty': 'True'},\n",
       " 'inputDatasets': [],\n",
       " 'runDefinition': {'script': 'titanic_training.py',\n",
       "  'scriptType': None,\n",
       "  'useAbsolutePath': False,\n",
       "  'arguments': [],\n",
       "  'sourceDirectoryDataStore': None,\n",
       "  'framework': 'Python',\n",
       "  'communicator': 'None',\n",
       "  'target': 'local',\n",
       "  'dataReferences': {},\n",
       "  'data': {},\n",
       "  'outputData': {},\n",
       "  'jobName': None,\n",
       "  'maxRunDurationSeconds': None,\n",
       "  'nodeCount': 1,\n",
       "  'environment': {'name': 'Experiment titanic-training-experiment Environment',\n",
       "   'version': 'Autosave_2020-09-14T08:10:43Z_165d38c7',\n",
       "   'python': {'interpreterPath': 'python',\n",
       "    'userManagedDependencies': False,\n",
       "    'condaDependencies': {'channels': ['anaconda', 'conda-forge'],\n",
       "     'dependencies': ['python=3.6.2',\n",
       "      {'pip': ['azureml-defaults']},\n",
       "      'scikit-learn'],\n",
       "     'name': 'azureml_4b824bcb98517d791c41923f24d65461'},\n",
       "    'baseCondaEnvironment': None},\n",
       "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'docker': {'baseImage': 'mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20200423.v1',\n",
       "    'platform': {'os': 'Linux', 'architecture': 'amd64'},\n",
       "    'baseDockerfile': None,\n",
       "    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n",
       "    'enabled': True,\n",
       "    'arguments': []},\n",
       "   'spark': {'repositories': [], 'packages': [], 'precachePackages': False},\n",
       "   'inferencingStackVersion': None},\n",
       "  'history': {'outputCollection': True,\n",
       "   'directoriesToWatch': ['logs'],\n",
       "   'enableMLflowTracking': True,\n",
       "   'snapshotProject': True},\n",
       "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'parallelTask': {'maxRetriesPerWorker': 0,\n",
       "   'workerCountPerNode': 1,\n",
       "   'terminalExitCodes': None,\n",
       "   'configuration': {}},\n",
       "  'amlCompute': {'name': None,\n",
       "   'vmSize': None,\n",
       "   'retainCluster': False,\n",
       "   'clusterMaxNodeCount': 1},\n",
       "  'aiSuperComputer': {'instanceType': None,\n",
       "   'frameworkImage': None,\n",
       "   'imageVersion': None,\n",
       "   'location': None},\n",
       "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
       "  'mpi': {'processCountPerNode': 1},\n",
       "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
       "  'containerInstance': {'region': None, 'cpuCores': 2, 'memoryGb': 3.5},\n",
       "  'exposedPorts': None,\n",
       "  'docker': {'useDocker': True,\n",
       "   'sharedVolumes': True,\n",
       "   'shmSize': '2g',\n",
       "   'arguments': []},\n",
       "  'cmk8sCompute': {'configuration': {}},\n",
       "  'cmAksCompute': {'configuration': {}}},\n",
       " 'logFiles': {'azureml-logs/60_control_log.txt': 'https://jtdp1009046233469.blob.core.windows.net/azureml/ExperimentRun/dcid.titanic-training-experiment_1600098729_8053c661/azureml-logs/60_control_log.txt?sv=2019-02-02&sr=b&sig=11ugVhaCfLDDePc1CNFn026WJqm1uW2W6Fhsjk2Ne4Q%3D&st=2020-09-14T15%3A42%3A35Z&se=2020-09-14T23%3A52%3A35Z&sp=r',\n",
       "  'azureml-logs/70_driver_log.txt': 'https://jtdp1009046233469.blob.core.windows.net/azureml/ExperimentRun/dcid.titanic-training-experiment_1600098729_8053c661/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=zSfWAnp%2FwW9VcNs3xa6ieqpeqvxuYwlPHWMh8j5D2kA%3D&st=2020-09-14T15%3A42%3A35Z&se=2020-09-14T23%3A52%3A35Z&sp=r',\n",
       "  'logs/azureml/10_azureml.log': 'https://jtdp1009046233469.blob.core.windows.net/azureml/ExperimentRun/dcid.titanic-training-experiment_1600098729_8053c661/logs/azureml/10_azureml.log?sv=2019-02-02&sr=b&sig=PTR47%2BZ8rDraTI0qs2%2B0SBdRdN5%2FX3RebTjXXx7mo8o%3D&st=2020-09-14T15%3A42%3A23Z&se=2020-09-14T23%3A52%3A23Z&sp=r'}}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.train.estimator import Estimator\n",
    "from azureml.core import Experiment\n",
    "\n",
    "# Create an Azure ML experiment in your workspace\n",
    "experiment = Experiment(workspace = ws, name = \"titanic-training-experiment\")\n",
    "\n",
    "# Create an estimator\n",
    "estimator = Estimator(source_directory=training_folder,\n",
    "                      entry_script='titanic_training.py',\n",
    "                      compute_target='local',\n",
    "                      conda_packages=['scikit-learn']\n",
    "                      )\n",
    "\n",
    "# Run the experiment based on the estimator\n",
    "run = experiment.submit(config=estimator)\n",
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16a47646f0a043018b9b7afe6cd4d1d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', '…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/titanic-training-experiment/runs/titanic-training-experiment_1600098729_8053c661?wsid=/subscriptions/9114a63e-9210-4e32-97ca-b7d9e8ac403d/resourcegroups/jt-dp100-ressources/workspaces/jt-dp100\", \"run_id\": \"titanic-training-experiment_1600098729_8053c661\", \"run_properties\": {\"run_id\": \"titanic-training-experiment_1600098729_8053c661\", \"created_utc\": \"2020-09-14T15:52:10.386061Z\", \"properties\": {\"_azureml.ComputeTargetType\": \"local\", \"ContentSnapshotId\": \"a74336a6-a407-4052-bf84-44ec5799e468\", \"azureml.git.repository_uri\": \"https://github.com/jtobelem-simplon/prepa-dp100.git\", \"mlflow.source.git.repoURL\": \"https://github.com/jtobelem-simplon/prepa-dp100.git\", \"azureml.git.branch\": \"master\", \"mlflow.source.git.branch\": \"master\", \"azureml.git.commit\": \"2d45093ddce878c37e597457953a961b3ad2cf28\", \"mlflow.source.git.commit\": \"2d45093ddce878c37e597457953a961b3ad2cf28\", \"azureml.git.dirty\": \"True\"}, \"tags\": {}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": \"2020-09-14T15:52:35.119591Z\", \"status\": \"Completed\", \"log_files\": {\"azureml-logs/60_control_log.txt\": \"https://jtdp1009046233469.blob.core.windows.net/azureml/ExperimentRun/dcid.titanic-training-experiment_1600098729_8053c661/azureml-logs/60_control_log.txt?sv=2019-02-02&sr=b&sig=11ugVhaCfLDDePc1CNFn026WJqm1uW2W6Fhsjk2Ne4Q%3D&st=2020-09-14T15%3A42%3A35Z&se=2020-09-14T23%3A52%3A35Z&sp=r\", \"azureml-logs/70_driver_log.txt\": \"https://jtdp1009046233469.blob.core.windows.net/azureml/ExperimentRun/dcid.titanic-training-experiment_1600098729_8053c661/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=zSfWAnp%2FwW9VcNs3xa6ieqpeqvxuYwlPHWMh8j5D2kA%3D&st=2020-09-14T15%3A42%3A35Z&se=2020-09-14T23%3A52%3A35Z&sp=r\", \"logs/azureml/10_azureml.log\": \"https://jtdp1009046233469.blob.core.windows.net/azureml/ExperimentRun/dcid.titanic-training-experiment_1600098729_8053c661/logs/azureml/10_azureml.log?sv=2019-02-02&sr=b&sig=PTR47%2BZ8rDraTI0qs2%2B0SBdRdN5%2FX3RebTjXXx7mo8o%3D&st=2020-09-14T15%3A42%3A23Z&se=2020-09-14T23%3A52%3A23Z&sp=r\"}, \"log_groups\": [[\"logs/azureml/10_azureml.log\"], [\"azureml-logs/60_control_log.txt\"], [\"azureml-logs/70_driver_log.txt\"]], \"run_duration\": \"0:00:24\"}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [{\"name\": \"mae\", \"run_id\": \"titanic-training-experiment_1600098729_8053c661\", \"categories\": [0], \"series\": [{\"data\": [0.1787709497206704]}]}, {\"name\": \"acc\", \"run_id\": \"titanic-training-experiment_1600098729_8053c661\", \"categories\": [0], \"series\": [{\"data\": [0.8212290502793296]}]}], \"run_logs\": \"[2020-09-14T15:52:17.076248] Entering context manager injector.\\n[context_manager_injector.py] Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError'], invocation=['titanic_training.py'])\\nStarting the daemon thread to refresh tokens in background for process with pid = 10\\nEntering Run History Context Manager.\\nCurrent directory:  /azureml-run\\nPreparing to call script [ titanic_training.py ] with arguments: []\\nAfter variable expansion, calling script [ titanic_training.py ] with arguments: []\\n\\nScript type = None\\nmae : 0.1787709497206704, accuracy : 0.8212290502793296\\nStarting the daemon thread to refresh tokens in background for process with pid = 10\\n\\n\\nThe experiment completed successfully. Finalizing run...\\nLogging experiment finalizing status in history service.\\n[2020-09-14T15:52:26.937967] TimeoutHandler __init__\\n[2020-09-14T15:52:26.938024] TimeoutHandler __enter__\\nCleaning up all outstanding Run operations, waiting 300.0 seconds\\n2 items cleaning up...\\nCleanup took 0.6417102813720703 seconds\\n[2020-09-14T15:52:28.708317] TimeoutHandler __exit__\\n\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.8.0\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrainement d'un modèle sur un cluster distant\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provisionnement ou récupération d'un cluster existant appelé \"aml-cluster\". Voir [tutoriel microsoft : partie 1](https://docs.microsoft.com/en-us/azure/machine-learning/tutorial-train-models-with-aml#train-on-a-remote-cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found compute target. just use it. aml-cluster\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import AmlCompute\n",
    "from azureml.core.compute import ComputeTarget\n",
    "import os\n",
    "\n",
    "# choose a name for your cluster\n",
    "compute_name = os.environ.get(\"AML_COMPUTE_CLUSTER_NAME\", \"aml-cluster\")\n",
    "compute_min_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MIN_NODES\", 0)\n",
    "compute_max_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MAX_NODES\", 4)\n",
    "\n",
    "# This example uses CPU VM. For using GPU VM, set SKU to STANDARD_NC6\n",
    "vm_size = os.environ.get(\"AML_COMPUTE_CLUSTER_SKU\", \"STANDARD_D2_V2\")\n",
    "\n",
    "\n",
    "if compute_name in ws.compute_targets:\n",
    "    compute_target = ws.compute_targets[compute_name]\n",
    "    if compute_target and type(compute_target) is AmlCompute:\n",
    "        print('found compute target. just use it. ' + compute_name)\n",
    "else:\n",
    "    print('creating a new compute target...')\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size=vm_size,\n",
    "                                                                min_nodes=compute_min_nodes,\n",
    "                                                                max_nodes=compute_max_nodes)\n",
    "\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(\n",
    "        ws, compute_name, provisioning_config)\n",
    "\n",
    "    # can poll for a minimum number of nodes and for a specific timeout.\n",
    "    # if no min node count is provided it will use the scale settings for the cluster\n",
    "    compute_target.wait_for_completion(\n",
    "        show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "\n",
    "    # For a more detailed view of current AmlCompute status, use get_status()\n",
    "    print(compute_target.get_status().serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Même estimator que dans la partie précédente mais avec le cluster dans la compute_target. Il va falloir provisionner le cluster (normalement 0 noeuds actifs initialement), cela peut prendre un peu de temps..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: titanic-training-experiment_1600098759_e3a93c06\n",
      "Web View: https://ml.azure.com/experiments/titanic-training-experiment/runs/titanic-training-experiment_1600098759_e3a93c06?wsid=/subscriptions/9114a63e-9210-4e32-97ca-b7d9e8ac403d/resourcegroups/jt-dp100-ressources/workspaces/jt-dp100\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_a806c78f4c1b8c0a1aaffbec106f01b4c49d4a143506450613d40e0b6fd17369_d.txt\n",
      "========================================================================================================================\n",
      "\n",
      "Using default tag: latest\n",
      "latest: Pulling from azureml/azureml_18a2c352852de1e0e7ad8b589dd0927b\n",
      "fe703b657a32: Pulling fs layer\n",
      "f9df1fafd224: Pulling fs layer\n",
      "a645a4b887f9: Pulling fs layer\n",
      "57db7fe0b522: Pulling fs layer\n",
      "20b5fabe4f63: Pulling fs layer\n",
      "22898513a7dc: Pulling fs layer\n",
      "b77f65fcd9d7: Pulling fs layer\n",
      "132ebd5cd5ca: Pulling fs layer\n",
      "01991399be72: Pulling fs layer\n",
      "60c58ca14ef7: Pulling fs layer\n",
      "ca339bb1ce1b: Pulling fs layer\n",
      "1e0eda0bd616: Pulling fs layer\n",
      "925b32604bbc: Pulling fs layer\n",
      "4a961b99c512: Pulling fs layer\n",
      "501a6ce88d04: Pulling fs layer\n",
      "87292195550e: Pulling fs layer\n",
      "ed370a864dfe: Pulling fs layer\n",
      "60c58ca14ef7: Waiting\n",
      "ca339bb1ce1b: Waiting\n",
      "1e0eda0bd616: Waiting\n",
      "925b32604bbc: Waiting\n",
      "4a961b99c512: Waiting\n",
      "501a6ce88d04: Waiting\n",
      "87292195550e: Waiting\n",
      "ed370a864dfe: Waiting\n",
      "22898513a7dc: Waiting\n",
      "b77f65fcd9d7: Waiting\n",
      "132ebd5cd5ca: Waiting\n",
      "01991399be72: Waiting\n",
      "57db7fe0b522: Waiting\n",
      "20b5fabe4f63: Waiting\n",
      "f9df1fafd224: Verifying Checksum\n",
      "f9df1fafd224: Download complete\n",
      "a645a4b887f9: Verifying Checksum\n",
      "a645a4b887f9: Download complete\n",
      "57db7fe0b522: Verifying Checksum\n",
      "57db7fe0b522: Download complete\n",
      "fe703b657a32: Verifying Checksum\n",
      "fe703b657a32: Download complete\n",
      "22898513a7dc: Verifying Checksum\n",
      "22898513a7dc: Download complete\n",
      "20b5fabe4f63: Verifying Checksum\n",
      "20b5fabe4f63: Download complete\n",
      "b77f65fcd9d7: Verifying Checksum\n",
      "b77f65fcd9d7: Download complete\n",
      "60c58ca14ef7: Verifying Checksum\n",
      "60c58ca14ef7: Download complete\n",
      "132ebd5cd5ca: Verifying Checksum\n",
      "132ebd5cd5ca: Download complete\n",
      "ca339bb1ce1b: Verifying Checksum\n",
      "ca339bb1ce1b: Download complete\n",
      "1e0eda0bd616: Verifying Checksum\n",
      "1e0eda0bd616: Download complete\n",
      "925b32604bbc: Verifying Checksum\n",
      "925b32604bbc: Download complete\n",
      "01991399be72: Verifying Checksum\n",
      "01991399be72: Download complete\n",
      "4a961b99c512: Verifying Checksum\n",
      "4a961b99c512: Download complete\n",
      "501a6ce88d04: Verifying Checksum\n",
      "501a6ce88d04: Download complete\n",
      "ed370a864dfe: Verifying Checksum\n",
      "ed370a864dfe: Download complete\n",
      "87292195550e: Verifying Checksum\n",
      "87292195550e: Download complete\n",
      "fe703b657a32: Pull complete\n",
      "f9df1fafd224: Pull complete\n",
      "a645a4b887f9: Pull complete\n",
      "57db7fe0b522: Pull complete\n",
      "20b5fabe4f63: Pull complete\n",
      "22898513a7dc: Pull complete\n",
      "b77f65fcd9d7: Pull complete\n",
      "132ebd5cd5ca: Pull complete\n",
      "01991399be72: Pull complete\n",
      "60c58ca14ef7: Pull complete\n",
      "ca339bb1ce1b: Pull complete\n",
      "1e0eda0bd616: Pull complete\n",
      "925b32604bbc: Pull complete\n",
      "4a961b99c512: Pull complete\n",
      "501a6ce88d04: Pull complete\n",
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_a806c78f4c1b8c0a1aaffbec106f01b4c49d4a143506450613d40e0b6fd17369_d.txt\n",
      "===============================================================================================================\n",
      "\n",
      "Entering job release. Current time:2020-09-14T15:58:43.087917\n",
      "Starting job release. Current time:2020-09-14T15:58:44.183498\n",
      "Logging experiment finalizing status in history service.\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 146\n",
      "[2020-09-14T15:58:44.197989] job release stage : upload_datastore starting...\n",
      "[{}] job release stage : start importing azureml.history._tracking in run_history_release.\n",
      "[2020-09-14T15:58:44.206413] job release stage : execute_job_release starting...\n",
      "[2020-09-14T15:58:44.207093] job release stage : copy_batchai_cached_logs starting...\n",
      "[2020-09-14T15:58:44.207722] job release stage : copy_batchai_cached_logs completed...\n",
      "[2020-09-14T15:58:44.210145] Entering context manager injector.\n",
      "[2020-09-14T15:58:44.211451] job release stage : upload_datastore completed...\n",
      "[2020-09-14T15:58:44.615446] job release stage : send_run_telemetry starting...\n",
      "[2020-09-14T15:58:44.993803] job release stage : send_run_telemetry completed...\n",
      "[2020-09-14T15:58:45.297709] job release stage : execute_job_release completed...\n",
      "Job release is complete. Current time:2020-09-14T15:58:45.297826\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: titanic-training-experiment_1600098759_e3a93c06\n",
      "Web View: https://ml.azure.com/experiments/titanic-training-experiment/runs/titanic-training-experiment_1600098759_e3a93c06?wsid=/subscriptions/9114a63e-9210-4e32-97ca-b7d9e8ac403d/resourcegroups/jt-dp100-ressources/workspaces/jt-dp100\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'titanic-training-experiment_1600098759_e3a93c06',\n",
       " 'target': 'aml-cluster',\n",
       " 'status': 'Completed',\n",
       " 'startTimeUtc': '2020-09-14T15:55:38.39858Z',\n",
       " 'endTimeUtc': '2020-09-14T15:58:53.971729Z',\n",
       " 'properties': {'_azureml.ComputeTargetType': 'amlcompute',\n",
       "  'ContentSnapshotId': '7e9b61ee-c8db-4a95-8ed9-a3e5a9f52964',\n",
       "  'azureml.git.repository_uri': 'https://github.com/jtobelem-simplon/prepa-dp100.git',\n",
       "  'mlflow.source.git.repoURL': 'https://github.com/jtobelem-simplon/prepa-dp100.git',\n",
       "  'azureml.git.branch': 'master',\n",
       "  'mlflow.source.git.branch': 'master',\n",
       "  'azureml.git.commit': '2d45093ddce878c37e597457953a961b3ad2cf28',\n",
       "  'mlflow.source.git.commit': '2d45093ddce878c37e597457953a961b3ad2cf28',\n",
       "  'azureml.git.dirty': 'True',\n",
       "  'ProcessInfoFile': 'azureml-logs/process_info.json',\n",
       "  'ProcessStatusFile': 'azureml-logs/process_status.json'},\n",
       " 'inputDatasets': [],\n",
       " 'runDefinition': {'script': 'titanic_training.py',\n",
       "  'scriptType': None,\n",
       "  'useAbsolutePath': False,\n",
       "  'arguments': [],\n",
       "  'sourceDirectoryDataStore': None,\n",
       "  'framework': 'Python',\n",
       "  'communicator': 'None',\n",
       "  'target': 'aml-cluster',\n",
       "  'dataReferences': {},\n",
       "  'data': {},\n",
       "  'outputData': {},\n",
       "  'jobName': None,\n",
       "  'maxRunDurationSeconds': None,\n",
       "  'nodeCount': 1,\n",
       "  'environment': {'name': 'Experiment titanic-training-experiment Environment',\n",
       "   'version': 'Autosave_2020-09-14T08:10:43Z_165d38c7',\n",
       "   'python': {'interpreterPath': 'python',\n",
       "    'userManagedDependencies': False,\n",
       "    'condaDependencies': {'channels': ['anaconda', 'conda-forge'],\n",
       "     'dependencies': ['python=3.6.2',\n",
       "      {'pip': ['azureml-defaults']},\n",
       "      'scikit-learn'],\n",
       "     'name': 'azureml_4b824bcb98517d791c41923f24d65461'},\n",
       "    'baseCondaEnvironment': None},\n",
       "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'docker': {'baseImage': 'mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20200423.v1',\n",
       "    'platform': {'os': 'Linux', 'architecture': 'amd64'},\n",
       "    'baseDockerfile': None,\n",
       "    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n",
       "    'enabled': True,\n",
       "    'arguments': []},\n",
       "   'spark': {'repositories': [], 'packages': [], 'precachePackages': False},\n",
       "   'inferencingStackVersion': None},\n",
       "  'history': {'outputCollection': True,\n",
       "   'directoriesToWatch': ['logs'],\n",
       "   'enableMLflowTracking': True,\n",
       "   'snapshotProject': True},\n",
       "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'parallelTask': {'maxRetriesPerWorker': 0,\n",
       "   'workerCountPerNode': 1,\n",
       "   'terminalExitCodes': None,\n",
       "   'configuration': {}},\n",
       "  'amlCompute': {'name': None,\n",
       "   'vmSize': None,\n",
       "   'retainCluster': False,\n",
       "   'clusterMaxNodeCount': 1},\n",
       "  'aiSuperComputer': {'instanceType': None,\n",
       "   'frameworkImage': None,\n",
       "   'imageVersion': None,\n",
       "   'location': None},\n",
       "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
       "  'mpi': {'processCountPerNode': 1},\n",
       "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
       "  'containerInstance': {'region': None, 'cpuCores': 2, 'memoryGb': 3.5},\n",
       "  'exposedPorts': None,\n",
       "  'docker': {'useDocker': True,\n",
       "   'sharedVolumes': True,\n",
       "   'shmSize': '2g',\n",
       "   'arguments': []},\n",
       "  'cmk8sCompute': {'configuration': {}},\n",
       "  'cmAksCompute': {'configuration': {}}},\n",
       " 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_a806c78f4c1b8c0a1aaffbec106f01b4c49d4a143506450613d40e0b6fd17369_d.txt': 'https://jtdp1009046233469.blob.core.windows.net/azureml/ExperimentRun/dcid.titanic-training-experiment_1600098759_e3a93c06/azureml-logs/55_azureml-execution-tvmps_a806c78f4c1b8c0a1aaffbec106f01b4c49d4a143506450613d40e0b6fd17369_d.txt?sv=2019-02-02&sr=b&sig=OphicA5%2Bo1QXLMBZYZu43Rs4qoPfTNBDQK1y1qxOgs4%3D&st=2020-09-14T15%3A49%3A17Z&se=2020-09-14T23%3A59%3A17Z&sp=r',\n",
       "  'azureml-logs/65_job_prep-tvmps_a806c78f4c1b8c0a1aaffbec106f01b4c49d4a143506450613d40e0b6fd17369_d.txt': 'https://jtdp1009046233469.blob.core.windows.net/azureml/ExperimentRun/dcid.titanic-training-experiment_1600098759_e3a93c06/azureml-logs/65_job_prep-tvmps_a806c78f4c1b8c0a1aaffbec106f01b4c49d4a143506450613d40e0b6fd17369_d.txt?sv=2019-02-02&sr=b&sig=wfxM%2BtGqhNqihCR4HzemhmUYqen4BgctO0dJ34FhJlI%3D&st=2020-09-14T15%3A49%3A17Z&se=2020-09-14T23%3A59%3A17Z&sp=r',\n",
       "  'azureml-logs/70_driver_log.txt': 'https://jtdp1009046233469.blob.core.windows.net/azureml/ExperimentRun/dcid.titanic-training-experiment_1600098759_e3a93c06/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=%2BGnupPiKModDYt2bQHewlosLpUWwu266NU7pREZDQ6E%3D&st=2020-09-14T15%3A49%3A17Z&se=2020-09-14T23%3A59%3A17Z&sp=r',\n",
       "  'azureml-logs/75_job_post-tvmps_a806c78f4c1b8c0a1aaffbec106f01b4c49d4a143506450613d40e0b6fd17369_d.txt': 'https://jtdp1009046233469.blob.core.windows.net/azureml/ExperimentRun/dcid.titanic-training-experiment_1600098759_e3a93c06/azureml-logs/75_job_post-tvmps_a806c78f4c1b8c0a1aaffbec106f01b4c49d4a143506450613d40e0b6fd17369_d.txt?sv=2019-02-02&sr=b&sig=JWeRC%2FaHTr3ExpbN6AW3i05LVrd9aXt0yFOFWs3Tjdg%3D&st=2020-09-14T15%3A49%3A17Z&se=2020-09-14T23%3A59%3A17Z&sp=r',\n",
       "  'azureml-logs/process_info.json': 'https://jtdp1009046233469.blob.core.windows.net/azureml/ExperimentRun/dcid.titanic-training-experiment_1600098759_e3a93c06/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=VJ3J4z3Mue5mGOYh8Q52%2FIy5F5PUhp6efUuLVqL4zqw%3D&st=2020-09-14T15%3A49%3A17Z&se=2020-09-14T23%3A59%3A17Z&sp=r',\n",
       "  'azureml-logs/process_status.json': 'https://jtdp1009046233469.blob.core.windows.net/azureml/ExperimentRun/dcid.titanic-training-experiment_1600098759_e3a93c06/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=Mv6DlZTfDdgfy58t4l0BCzfS66sLPemaPQsirNPhq9o%3D&st=2020-09-14T15%3A49%3A17Z&se=2020-09-14T23%3A59%3A17Z&sp=r',\n",
       "  'logs/azureml/109_azureml.log': 'https://jtdp1009046233469.blob.core.windows.net/azureml/ExperimentRun/dcid.titanic-training-experiment_1600098759_e3a93c06/logs/azureml/109_azureml.log?sv=2019-02-02&sr=b&sig=82R8ovyxyRbRNAmAm8Xe%2F2MPZtLWvcW0O8XmqjXjDzo%3D&st=2020-09-14T15%3A49%3A17Z&se=2020-09-14T23%3A59%3A17Z&sp=r',\n",
       "  'logs/azureml/job_prep_azureml.log': 'https://jtdp1009046233469.blob.core.windows.net/azureml/ExperimentRun/dcid.titanic-training-experiment_1600098759_e3a93c06/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=K%2FI7oh7yVxaWN6YyzW7Dgh1T6Pt%2Frc7i%2FoTOYW%2BLFQA%3D&st=2020-09-14T15%3A49%3A17Z&se=2020-09-14T23%3A59%3A17Z&sp=r',\n",
       "  'logs/azureml/job_release_azureml.log': 'https://jtdp1009046233469.blob.core.windows.net/azureml/ExperimentRun/dcid.titanic-training-experiment_1600098759_e3a93c06/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=DwbKA77kkVyEMkl1%2FHzXbF%2Fk6gG2GGQSzZvf8lCeEg4%3D&st=2020-09-14T15%3A49%3A17Z&se=2020-09-14T23%3A59%3A17Z&sp=r'}}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.train.estimator import Estimator\n",
    "from azureml.core import Experiment\n",
    "\n",
    "# Create an Azure ML experiment in your workspace\n",
    "experiment = Experiment(workspace = ws, name = \"titanic-training-experiment\")\n",
    "\n",
    "# Create an estimator\n",
    "estimator = Estimator(source_directory=training_folder,\n",
    "                      entry_script='titanic_training.py',\n",
    "                      compute_target=compute_target,\n",
    "                      conda_packages=['scikit-learn']\n",
    "                      )\n",
    "\n",
    "# Run the experiment based on the estimator\n",
    "run = experiment.submit(config=estimator)\n",
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b08bde2ace68459096ada08a23feee2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', '…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/titanic-training-experiment/runs/titanic-training-experiment_1600098759_e3a93c06?wsid=/subscriptions/9114a63e-9210-4e32-97ca-b7d9e8ac403d/resourcegroups/jt-dp100-ressources/workspaces/jt-dp100\", \"run_id\": \"titanic-training-experiment_1600098759_e3a93c06\", \"run_properties\": {\"run_id\": \"titanic-training-experiment_1600098759_e3a93c06\", \"created_utc\": \"2020-09-14T15:52:41.328325Z\", \"properties\": {\"_azureml.ComputeTargetType\": \"amlcompute\", \"ContentSnapshotId\": \"7e9b61ee-c8db-4a95-8ed9-a3e5a9f52964\", \"azureml.git.repository_uri\": \"https://github.com/jtobelem-simplon/prepa-dp100.git\", \"mlflow.source.git.repoURL\": \"https://github.com/jtobelem-simplon/prepa-dp100.git\", \"azureml.git.branch\": \"master\", \"mlflow.source.git.branch\": \"master\", \"azureml.git.commit\": \"2d45093ddce878c37e597457953a961b3ad2cf28\", \"mlflow.source.git.commit\": \"2d45093ddce878c37e597457953a961b3ad2cf28\", \"azureml.git.dirty\": \"True\", \"ProcessInfoFile\": \"azureml-logs/process_info.json\", \"ProcessStatusFile\": \"azureml-logs/process_status.json\"}, \"tags\": {\"_aml_system_ComputeTargetStatus\": \"{\\\"AllocationState\\\":\\\"resizing\\\",\\\"PreparingNodeCount\\\":0,\\\"RunningNodeCount\\\":0,\\\"CurrentNodeCount\\\":0}\"}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": \"2020-09-14T15:58:53.971729Z\", \"status\": \"Completed\", \"log_files\": {\"azureml-logs/55_azureml-execution-tvmps_a806c78f4c1b8c0a1aaffbec106f01b4c49d4a143506450613d40e0b6fd17369_d.txt\": \"https://jtdp1009046233469.blob.core.windows.net/azureml/ExperimentRun/dcid.titanic-training-experiment_1600098759_e3a93c06/azureml-logs/55_azureml-execution-tvmps_a806c78f4c1b8c0a1aaffbec106f01b4c49d4a143506450613d40e0b6fd17369_d.txt?sv=2019-02-02&sr=b&sig=OphicA5%2Bo1QXLMBZYZu43Rs4qoPfTNBDQK1y1qxOgs4%3D&st=2020-09-14T15%3A49%3A17Z&se=2020-09-14T23%3A59%3A17Z&sp=r\", \"azureml-logs/65_job_prep-tvmps_a806c78f4c1b8c0a1aaffbec106f01b4c49d4a143506450613d40e0b6fd17369_d.txt\": \"https://jtdp1009046233469.blob.core.windows.net/azureml/ExperimentRun/dcid.titanic-training-experiment_1600098759_e3a93c06/azureml-logs/65_job_prep-tvmps_a806c78f4c1b8c0a1aaffbec106f01b4c49d4a143506450613d40e0b6fd17369_d.txt?sv=2019-02-02&sr=b&sig=wfxM%2BtGqhNqihCR4HzemhmUYqen4BgctO0dJ34FhJlI%3D&st=2020-09-14T15%3A49%3A17Z&se=2020-09-14T23%3A59%3A17Z&sp=r\", \"azureml-logs/70_driver_log.txt\": \"https://jtdp1009046233469.blob.core.windows.net/azureml/ExperimentRun/dcid.titanic-training-experiment_1600098759_e3a93c06/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=%2BGnupPiKModDYt2bQHewlosLpUWwu266NU7pREZDQ6E%3D&st=2020-09-14T15%3A49%3A17Z&se=2020-09-14T23%3A59%3A17Z&sp=r\", \"azureml-logs/75_job_post-tvmps_a806c78f4c1b8c0a1aaffbec106f01b4c49d4a143506450613d40e0b6fd17369_d.txt\": \"https://jtdp1009046233469.blob.core.windows.net/azureml/ExperimentRun/dcid.titanic-training-experiment_1600098759_e3a93c06/azureml-logs/75_job_post-tvmps_a806c78f4c1b8c0a1aaffbec106f01b4c49d4a143506450613d40e0b6fd17369_d.txt?sv=2019-02-02&sr=b&sig=JWeRC%2FaHTr3ExpbN6AW3i05LVrd9aXt0yFOFWs3Tjdg%3D&st=2020-09-14T15%3A49%3A17Z&se=2020-09-14T23%3A59%3A17Z&sp=r\", \"azureml-logs/process_info.json\": \"https://jtdp1009046233469.blob.core.windows.net/azureml/ExperimentRun/dcid.titanic-training-experiment_1600098759_e3a93c06/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=VJ3J4z3Mue5mGOYh8Q52%2FIy5F5PUhp6efUuLVqL4zqw%3D&st=2020-09-14T15%3A49%3A17Z&se=2020-09-14T23%3A59%3A17Z&sp=r\", \"azureml-logs/process_status.json\": \"https://jtdp1009046233469.blob.core.windows.net/azureml/ExperimentRun/dcid.titanic-training-experiment_1600098759_e3a93c06/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=Mv6DlZTfDdgfy58t4l0BCzfS66sLPemaPQsirNPhq9o%3D&st=2020-09-14T15%3A49%3A17Z&se=2020-09-14T23%3A59%3A17Z&sp=r\", \"logs/azureml/109_azureml.log\": \"https://jtdp1009046233469.blob.core.windows.net/azureml/ExperimentRun/dcid.titanic-training-experiment_1600098759_e3a93c06/logs/azureml/109_azureml.log?sv=2019-02-02&sr=b&sig=82R8ovyxyRbRNAmAm8Xe%2F2MPZtLWvcW0O8XmqjXjDzo%3D&st=2020-09-14T15%3A49%3A17Z&se=2020-09-14T23%3A59%3A17Z&sp=r\", \"logs/azureml/job_prep_azureml.log\": \"https://jtdp1009046233469.blob.core.windows.net/azureml/ExperimentRun/dcid.titanic-training-experiment_1600098759_e3a93c06/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=K%2FI7oh7yVxaWN6YyzW7Dgh1T6Pt%2Frc7i%2FoTOYW%2BLFQA%3D&st=2020-09-14T15%3A49%3A17Z&se=2020-09-14T23%3A59%3A17Z&sp=r\", \"logs/azureml/job_release_azureml.log\": \"https://jtdp1009046233469.blob.core.windows.net/azureml/ExperimentRun/dcid.titanic-training-experiment_1600098759_e3a93c06/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=DwbKA77kkVyEMkl1%2FHzXbF%2Fk6gG2GGQSzZvf8lCeEg4%3D&st=2020-09-14T15%3A49%3A17Z&se=2020-09-14T23%3A59%3A17Z&sp=r\"}, \"log_groups\": [[\"azureml-logs/process_info.json\", \"azureml-logs/process_status.json\", \"logs/azureml/job_prep_azureml.log\", \"logs/azureml/job_release_azureml.log\"], [\"azureml-logs/55_azureml-execution-tvmps_a806c78f4c1b8c0a1aaffbec106f01b4c49d4a143506450613d40e0b6fd17369_d.txt\"], [\"azureml-logs/65_job_prep-tvmps_a806c78f4c1b8c0a1aaffbec106f01b4c49d4a143506450613d40e0b6fd17369_d.txt\"], [\"azureml-logs/70_driver_log.txt\"], [\"azureml-logs/75_job_post-tvmps_a806c78f4c1b8c0a1aaffbec106f01b4c49d4a143506450613d40e0b6fd17369_d.txt\"], [\"logs/azureml/109_azureml.log\"]], \"run_duration\": \"0:06:12\"}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [{\"name\": \"mae\", \"run_id\": \"titanic-training-experiment_1600098759_e3a93c06\", \"categories\": [0], \"series\": [{\"data\": [0.1787709497206704]}]}, {\"name\": \"acc\", \"run_id\": \"titanic-training-experiment_1600098759_e3a93c06\", \"categories\": [0], \"series\": [{\"data\": [0.8212290502793296]}]}], \"run_logs\": \"2020-09-14 15:58:35,968|azureml|DEBUG|Inputs:: kwargs: {'OutputCollection': True, 'EnableMLflowTracking': True, 'snapshotProject': True, 'only_in_process_features': True, 'skip_track_logs_dir': True}, track_folders: None, deny_list: None, directories_to_watch: []\\n2020-09-14 15:58:35,968|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Execution target type: batchai\\n2020-09-14 15:58:35,976|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Failed to import pyspark with error: No module named 'pyspark'\\n2020-09-14 15:58:35,976|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Pinning working directory for filesystems: ['pyfs']\\n2020-09-14 15:58:36,295|azureml.core.run|DEBUG|Adding new factory <function ScriptRun._from_run_dto at 0x7fe9353fe378> for run source azureml.scriptrun\\n2020-09-14 15:58:36,328|azureml.core.authentication.TokenRefresherDaemon|DEBUG|Starting daemon and triggering first instance\\n2020-09-14 15:58:36,336|azureml._restclient.clientbase|INFO|Created a worker pool for first use\\n2020-09-14 15:58:36,336|azureml.core.authentication|DEBUG|Time to expire 1814044.663041 seconds\\n2020-09-14 15:58:36,337|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.experiments.azureml.net.\\n2020-09-14 15:58:36,337|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.experiments.azureml.net.\\n2020-09-14 15:58:36,337|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.experiments.azureml.net.\\n2020-09-14 15:58:36,337|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.experiments.azureml.net.\\n2020-09-14 15:58:36,370|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.experiments.azureml.net.\\n2020-09-14 15:58:36,370|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.experiments.azureml.net.\\n2020-09-14 15:58:36,370|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.experiments.azureml.net.\\n2020-09-14 15:58:36,402|azureml._SubmittedRun#titanic-training-experiment_1600098759_e3a93c06.RunHistoryFacade.RunClient.get-async:False|DEBUG|[START]\\n2020-09-14 15:58:36,754|azureml._SubmittedRun#titanic-training-experiment_1600098759_e3a93c06.RunHistoryFacade.RunClient.get-async:False|DEBUG|[STOP]\\n2020-09-14 15:58:36,755|azureml._SubmittedRun#titanic-training-experiment_1600098759_e3a93c06|DEBUG|Constructing run from dto. type: azureml.scriptrun, source: None, props: {'_azureml.ComputeTargetType': 'amlcompute', 'ContentSnapshotId': '7e9b61ee-c8db-4a95-8ed9-a3e5a9f52964', 'azureml.git.repository_uri': 'https://github.com/jtobelem-simplon/prepa-dp100.git', 'mlflow.source.git.repoURL': 'https://github.com/jtobelem-simplon/prepa-dp100.git', 'azureml.git.branch': 'master', 'mlflow.source.git.branch': 'master', 'azureml.git.commit': '2d45093ddce878c37e597457953a961b3ad2cf28', 'mlflow.source.git.commit': '2d45093ddce878c37e597457953a961b3ad2cf28', 'azureml.git.dirty': 'True', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}\\n2020-09-14 15:58:36,765|azureml._SubmittedRun#titanic-training-experiment_1600098759_e3a93c06.RunContextManager|DEBUG|Valid logs dir, setting up content loader\\n2020-09-14 15:58:36,765|azureml|WARNING|Could not import azureml.mlflow or azureml.contrib.mlflow mlflow APIs will not run against AzureML services.  Add azureml-mlflow as a conda dependency for the run if this behavior is desired\\n2020-09-14 15:58:36,766|azureml.WorkerPool|DEBUG|[START]\\n2020-09-14 15:58:36,766|azureml.SendRunKillSignal|DEBUG|[START]\\n2020-09-14 15:58:36,766|azureml.RunStatusContext|DEBUG|[START]\\n2020-09-14 15:58:36,766|azureml._SubmittedRun#titanic-training-experiment_1600098759_e3a93c06.RunContextManager.RunStatusContext|DEBUG|[START]\\n2020-09-14 15:58:36,766|azureml.WorkingDirectoryCM|DEBUG|[START]\\n2020-09-14 15:58:36,766|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|[START]\\n2020-09-14 15:58:36,766|azureml.history._tracking.PythonWorkingDirectory|INFO|Current working dir: /mnt/batch/tasks/shared/LS_root/jobs/jt-dp100/azureml/titanic-training-experiment_1600098759_e3a93c06/mounts/workspaceblobstore/azureml/titanic-training-experiment_1600098759_e3a93c06\\n2020-09-14 15:58:36,767|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling pyfs\\n2020-09-14 15:58:36,767|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Storing working dir for pyfs as /mnt/batch/tasks/shared/LS_root/jobs/jt-dp100/azureml/titanic-training-experiment_1600098759_e3a93c06/mounts/workspaceblobstore/azureml/titanic-training-experiment_1600098759_e3a93c06\\n2020-09-14 15:58:37,718|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.experiments.azureml.net.\\n2020-09-14 15:58:37,718|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.experiments.azureml.net.\\n2020-09-14 15:58:37,718|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.experiments.azureml.net.\\n2020-09-14 15:58:37,718|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.experiments.azureml.net.\\n2020-09-14 15:58:37,719|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.experiments.azureml.net.\\n2020-09-14 15:58:37,719|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.experiments.azureml.net.\\n2020-09-14 15:58:37,719|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.experiments.azureml.net.\\n2020-09-14 15:58:37,728|azureml._run_impl.run_history_facade|DEBUG|Created a static thread pool for RunHistoryFacade class\\n2020-09-14 15:58:37,750|azureml._SubmittedRun#titanic-training-experiment_1600098759_e3a93c06.RunHistoryFacade.RunClient.get-async:False|DEBUG|[START]\\n2020-09-14 15:58:37,962|azureml._SubmittedRun#titanic-training-experiment_1600098759_e3a93c06.RunHistoryFacade.RunClient.get-async:False|DEBUG|[STOP]\\n2020-09-14 15:58:37,963|azureml._SubmittedRun#titanic-training-experiment_1600098759_e3a93c06|DEBUG|Constructing run from dto. type: azureml.scriptrun, source: None, props: {'_azureml.ComputeTargetType': 'amlcompute', 'ContentSnapshotId': '7e9b61ee-c8db-4a95-8ed9-a3e5a9f52964', 'azureml.git.repository_uri': 'https://github.com/jtobelem-simplon/prepa-dp100.git', 'mlflow.source.git.repoURL': 'https://github.com/jtobelem-simplon/prepa-dp100.git', 'azureml.git.branch': 'master', 'mlflow.source.git.branch': 'master', 'azureml.git.commit': '2d45093ddce878c37e597457953a961b3ad2cf28', 'mlflow.source.git.commit': '2d45093ddce878c37e597457953a961b3ad2cf28', 'azureml.git.dirty': 'True', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}\\n2020-09-14 15:58:37,963|azureml._SubmittedRun#titanic-training-experiment_1600098759_e3a93c06.RunContextManager|DEBUG|Valid logs dir, setting up content loader\\n2020-09-14 15:58:38,155|azureml._SubmittedRun#titanic-training-experiment_1600098759_e3a93c06.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2020-09-14 15:58:38,155|azureml._SubmittedRun#titanic-training-experiment_1600098759_e3a93c06.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.PostMetricsBatchV2Daemon|DEBUG|Starting daemon and triggering first instance\\n2020-09-14 15:58:38,156|azureml._SubmittedRun#titanic-training-experiment_1600098759_e3a93c06.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2020-09-14 15:58:38,255|azureml._SubmittedRun#titanic-training-experiment_1600098759_e3a93c06|INFO|complete is not setting status for submitted runs.\\n2020-09-14 15:58:38,255|azureml._SubmittedRun#titanic-training-experiment_1600098759_e3a93c06.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2020-09-14 15:58:38,255|azureml._SubmittedRun#titanic-training-experiment_1600098759_e3a93c06.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2020-09-14 15:58:38,256|azureml._SubmittedRun#titanic-training-experiment_1600098759_e3a93c06.RunHistoryFacade.MetricsClient.PostMetricsBatch.PostMetricsBatchDaemon|DEBUG|Starting daemon and triggering first instance\\n2020-09-14 15:58:38,256|azureml._SubmittedRun#titanic-training-experiment_1600098759_e3a93c06.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2020-09-14 15:58:38,256|azureml._SubmittedRun#titanic-training-experiment_1600098759_e3a93c06.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2020-09-14 15:58:38,256|azureml._SubmittedRun#titanic-training-experiment_1600098759_e3a93c06.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300 is different from task queue timeout 120, using flush timeout\\n2020-09-14 15:58:38,256|azureml._SubmittedRun#titanic-training-experiment_1600098759_e3a93c06.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 300 seconds on tasks: [].\\n2020-09-14 15:58:38,256|azureml._SubmittedRun#titanic-training-experiment_1600098759_e3a93c06.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2020-09-14 15:58:38,256|azureml._SubmittedRun#titanic-training-experiment_1600098759_e3a93c06.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2020-09-14 15:58:38,256|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Start]\\n2020-09-14 15:58:38,257|azureml.BatchTaskQueueAdd_1_Batches.WorkerPool|DEBUG|submitting future: _handle_batch\\n2020-09-14 15:58:38,257|azureml._SubmittedRun#titanic-training-experiment_1600098759_e3a93c06.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|Batch size 2.\\n2020-09-14 15:58:38,257|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch|DEBUG|Using basic handler - no exception handling\\n2020-09-14 15:58:38,257|azureml._restclient.clientbase.WorkerPool|DEBUG|submitting future: _log_batch_v2\\n2020-09-14 15:58:38,257|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|Adding task 0__handle_batch to queue of approximate size: 0\\n2020-09-14 15:58:38,258|azureml._SubmittedRun#titanic-training-experiment_1600098759_e3a93c06.RunHistoryFacade.MetricsClient.post_run_metrics-async:False|DEBUG|[START]\\n2020-09-14 15:58:38,258|azureml._SubmittedRun#titanic-training-experiment_1600098759_e3a93c06.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2|DEBUG|Using basic handler - no exception handling\\n2020-09-14 15:58:38,258|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Stop] - waiting default timeout\\n2020-09-14 15:58:38,261|azureml._SubmittedRun#titanic-training-experiment_1600098759_e3a93c06.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|Adding task 0__log_batch_v2 to queue of approximate size: 0\\n2020-09-14 15:58:38,261|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[START]\\n2020-09-14 15:58:38,262|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Overriding default flush timeout from None to 120\\n2020-09-14 15:58:38,262|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Waiting 120 seconds on tasks: [AsyncTask(0__handle_batch)].\\n2020-09-14 15:58:38,262|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[START]\\n2020-09-14 15:58:38,262|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|Awaiter is BatchTaskQueueAdd_1_Batches\\n2020-09-14 15:58:38,262|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[STOP]\\n2020-09-14 15:58:38,262|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|\\n2020-09-14 15:58:38,262|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[STOP]\\n2020-09-14 15:58:38,262|azureml._SubmittedRun#titanic-training-experiment_1600098759_e3a93c06.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2020-09-14 15:58:38,262|azureml._SubmittedRun#titanic-training-experiment_1600098759_e3a93c06.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300 is different from task queue timeout 120, using flush timeout\\n2020-09-14 15:58:38,263|azureml._SubmittedRun#titanic-training-experiment_1600098759_e3a93c06.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 300 seconds on tasks: [AsyncTask(0__log_batch_v2)].\\n2020-09-14 15:58:38,915|azureml._SubmittedRun#titanic-training-experiment_1600098759_e3a93c06.RunHistoryFacade.MetricsClient.post_run_metrics-async:False|DEBUG|[STOP]\\n2020-09-14 15:58:39,014|azureml._SubmittedRun#titanic-training-experiment_1600098759_e3a93c06.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2.WaitingTask|DEBUG|[START]\\n2020-09-14 15:58:39,014|azureml._SubmittedRun#titanic-training-experiment_1600098759_e3a93c06.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2.WaitingTask|DEBUG|Awaiter is PostMetricsBatchV2\\n2020-09-14 15:58:39,014|azureml._SubmittedRun#titanic-training-experiment_1600098759_e3a93c06.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2.WaitingTask|DEBUG|[STOP]\\n2020-09-14 15:58:39,014|azureml._SubmittedRun#titanic-training-experiment_1600098759_e3a93c06.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|Waiting on task: 0__log_batch_v2.\\n1 tasks left. Current duration of flush 9.72747802734375e-05 seconds.\\nWaiting on task: 0__log_batch_v2.\\n1 tasks left. Current duration of flush 0.25043416023254395 seconds.\\nWaiting on task: 0__log_batch_v2.\\n1 tasks left. Current duration of flush 0.5008494853973389 seconds.\\n\\n2020-09-14 15:58:39,014|azureml._SubmittedRun#titanic-training-experiment_1600098759_e3a93c06.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2020-09-14 15:58:39,014|azureml._SubmittedRun#titanic-training-experiment_1600098759_e3a93c06.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2020-09-14 15:58:39,015|azureml._SubmittedRun#titanic-training-experiment_1600098759_e3a93c06.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2020-09-14 15:58:39,461|azureml._SubmittedRun#titanic-training-experiment_1600098759_e3a93c06.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2020-09-14 15:58:39,568|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling pyfs\\n2020-09-14 15:58:39,569|azureml.history._tracking.PythonWorkingDirectory|INFO|Current working dir: /mnt/batch/tasks/shared/LS_root/jobs/jt-dp100/azureml/titanic-training-experiment_1600098759_e3a93c06/mounts/workspaceblobstore/azureml/titanic-training-experiment_1600098759_e3a93c06\\n2020-09-14 15:58:39,569|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Reverting working dir from /mnt/batch/tasks/shared/LS_root/jobs/jt-dp100/azureml/titanic-training-experiment_1600098759_e3a93c06/mounts/workspaceblobstore/azureml/titanic-training-experiment_1600098759_e3a93c06 to /mnt/batch/tasks/shared/LS_root/jobs/jt-dp100/azureml/titanic-training-experiment_1600098759_e3a93c06/mounts/workspaceblobstore/azureml/titanic-training-experiment_1600098759_e3a93c06\\n2020-09-14 15:58:39,569|azureml.history._tracking.PythonWorkingDirectory|INFO|Working dir is already updated /mnt/batch/tasks/shared/LS_root/jobs/jt-dp100/azureml/titanic-training-experiment_1600098759_e3a93c06/mounts/workspaceblobstore/azureml/titanic-training-experiment_1600098759_e3a93c06\\n2020-09-14 15:58:39,569|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|[STOP]\\n2020-09-14 15:58:39,569|azureml.WorkingDirectoryCM|DEBUG|[STOP]\\n2020-09-14 15:58:39,569|azureml._SubmittedRun#titanic-training-experiment_1600098759_e3a93c06|INFO|complete is not setting status for submitted runs.\\n2020-09-14 15:58:39,569|azureml._SubmittedRun#titanic-training-experiment_1600098759_e3a93c06.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2020-09-14 15:58:39,569|azureml._SubmittedRun#titanic-training-experiment_1600098759_e3a93c06.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2020-09-14 15:58:39,570|azureml._SubmittedRun#titanic-training-experiment_1600098759_e3a93c06.RunHistoryFacade.MetricsClient.PostMetricsBatch.PostMetricsBatchDaemon|DEBUG|Starting daemon and triggering first instance\\n2020-09-14 15:58:39,570|azureml._SubmittedRun#titanic-training-experiment_1600098759_e3a93c06.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2020-09-14 15:58:39,570|azureml._SubmittedRun#titanic-training-experiment_1600098759_e3a93c06.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2020-09-14 15:58:39,570|azureml._SubmittedRun#titanic-training-experiment_1600098759_e3a93c06.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300 is different from task queue timeout 120, using flush timeout\\n2020-09-14 15:58:39,571|azureml._SubmittedRun#titanic-training-experiment_1600098759_e3a93c06.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 300 seconds on tasks: [].\\n2020-09-14 15:58:39,571|azureml._SubmittedRun#titanic-training-experiment_1600098759_e3a93c06.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2020-09-14 15:58:39,571|azureml._SubmittedRun#titanic-training-experiment_1600098759_e3a93c06.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2020-09-14 15:58:39,571|azureml._SubmittedRun#titanic-training-experiment_1600098759_e3a93c06.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2020-09-14 15:58:39,571|azureml._SubmittedRun#titanic-training-experiment_1600098759_e3a93c06.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.PostMetricsBatchV2Daemon|DEBUG|Starting daemon and triggering first instance\\n2020-09-14 15:58:39,572|azureml._SubmittedRun#titanic-training-experiment_1600098759_e3a93c06.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2020-09-14 15:58:39,572|azureml._SubmittedRun#titanic-training-experiment_1600098759_e3a93c06.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2020-09-14 15:58:39,572|azureml._SubmittedRun#titanic-training-experiment_1600098759_e3a93c06.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300 is different from task queue timeout 120, using flush timeout\\n2020-09-14 15:58:39,572|azureml._SubmittedRun#titanic-training-experiment_1600098759_e3a93c06.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 300 seconds on tasks: [].\\n2020-09-14 15:58:39,572|azureml._SubmittedRun#titanic-training-experiment_1600098759_e3a93c06.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|\\n2020-09-14 15:58:39,573|azureml._SubmittedRun#titanic-training-experiment_1600098759_e3a93c06.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2020-09-14 15:58:39,573|azureml._SubmittedRun#titanic-training-experiment_1600098759_e3a93c06.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2020-09-14 15:58:39,573|azureml._SubmittedRun#titanic-training-experiment_1600098759_e3a93c06.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2020-09-14 15:58:39,668|azureml._SubmittedRun#titanic-training-experiment_1600098759_e3a93c06.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2020-09-14 15:58:39,668|azureml.RunStatusContext|DEBUG|[STOP]\\n2020-09-14 15:58:39,668|azureml._SubmittedRun#titanic-training-experiment_1600098759_e3a93c06.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2020-09-14 15:58:39,668|azureml._SubmittedRun#titanic-training-experiment_1600098759_e3a93c06.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2020-09-14 15:58:39,668|azureml._SubmittedRun#titanic-training-experiment_1600098759_e3a93c06.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300.0 is different from task queue timeout 120, using flush timeout\\n2020-09-14 15:58:39,669|azureml._SubmittedRun#titanic-training-experiment_1600098759_e3a93c06.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 300.0 seconds on tasks: [].\\n2020-09-14 15:58:39,669|azureml._SubmittedRun#titanic-training-experiment_1600098759_e3a93c06.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2020-09-14 15:58:39,669|azureml._SubmittedRun#titanic-training-experiment_1600098759_e3a93c06.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2020-09-14 15:58:39,669|azureml._SubmittedRun#titanic-training-experiment_1600098759_e3a93c06.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2020-09-14 15:58:39,669|azureml._SubmittedRun#titanic-training-experiment_1600098759_e3a93c06.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300.0 is different from task queue timeout 120, using flush timeout\\n2020-09-14 15:58:39,669|azureml._SubmittedRun#titanic-training-experiment_1600098759_e3a93c06.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 300.0 seconds on tasks: [].\\n2020-09-14 15:58:39,669|azureml._SubmittedRun#titanic-training-experiment_1600098759_e3a93c06.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|\\n2020-09-14 15:58:39,669|azureml._SubmittedRun#titanic-training-experiment_1600098759_e3a93c06.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2020-09-14 15:58:39,669|azureml._SubmittedRun#titanic-training-experiment_1600098759_e3a93c06.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2020-09-14 15:58:39,669|azureml._SubmittedRun#titanic-training-experiment_1600098759_e3a93c06.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2020-09-14 15:58:39,792|azureml._SubmittedRun#titanic-training-experiment_1600098759_e3a93c06.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2020-09-14 15:58:39,792|azureml._SubmittedRun#titanic-training-experiment_1600098759_e3a93c06.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2020-09-14 15:58:39,793|azureml._SubmittedRun#titanic-training-experiment_1600098759_e3a93c06.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2020-09-14 15:58:39,793|azureml._SubmittedRun#titanic-training-experiment_1600098759_e3a93c06.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300.0 is different from task queue timeout 120, using flush timeout\\n2020-09-14 15:58:39,793|azureml._SubmittedRun#titanic-training-experiment_1600098759_e3a93c06.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 300.0 seconds on tasks: [].\\n2020-09-14 15:58:39,793|azureml._SubmittedRun#titanic-training-experiment_1600098759_e3a93c06.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2020-09-14 15:58:39,793|azureml._SubmittedRun#titanic-training-experiment_1600098759_e3a93c06.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2020-09-14 15:58:39,793|azureml._SubmittedRun#titanic-training-experiment_1600098759_e3a93c06.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2020-09-14 15:58:39,793|azureml._SubmittedRun#titanic-training-experiment_1600098759_e3a93c06.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300.0 is different from task queue timeout 120, using flush timeout\\n2020-09-14 15:58:39,794|azureml._SubmittedRun#titanic-training-experiment_1600098759_e3a93c06.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 300.0 seconds on tasks: [].\\n2020-09-14 15:58:39,794|azureml._SubmittedRun#titanic-training-experiment_1600098759_e3a93c06.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|\\n2020-09-14 15:58:39,794|azureml._SubmittedRun#titanic-training-experiment_1600098759_e3a93c06.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2020-09-14 15:58:39,794|azureml._SubmittedRun#titanic-training-experiment_1600098759_e3a93c06.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2020-09-14 15:58:39,794|azureml._SubmittedRun#titanic-training-experiment_1600098759_e3a93c06.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2020-09-14 15:58:39,881|azureml._SubmittedRun#titanic-training-experiment_1600098759_e3a93c06.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2020-09-14 15:58:39,882|azureml.SendRunKillSignal|DEBUG|[STOP]\\n2020-09-14 15:58:39,882|azureml.HistoryTrackingWorkerPool.WorkerPoolShutdown|DEBUG|[START]\\n2020-09-14 15:58:39,882|azureml.HistoryTrackingWorkerPool.WorkerPoolShutdown|DEBUG|[STOP]\\n2020-09-14 15:58:39,882|azureml.WorkerPool|DEBUG|[STOP]\\n\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.8.0\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enregistrer le modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(workspace=Workspace.create(name='jt-dp100', subscription_id='9114a63e-9210-4e32-97ca-b7d9e8ac403d', resource_group='jt-dp100-ressources'), name=titanic_model, id=titanic_model:2, version=2, tags={'Training context': 'Estimator'}, properties={'Mean Absolute Error': '0.1787709497206704', 'Accuracy': '0.8212290502793296'})"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core import Model\n",
    "\n",
    "# Register the model\n",
    "run.register_model(model_path='outputs/titanic_model.pkl', model_name='titanic_model',\n",
    "                   tags={'Training context':'Estimator'},\n",
    "                   properties={'Mean Absolute Error': run.get_metrics()['mae'], 'Accuracy': run.get_metrics()['acc']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "titanic_model version: 2\n",
      "\t Training context : Estimator\n",
      "\t Mean Absolute Error : 0.1787709497206704\n",
      "\t Accuracy : 0.8212290502793296\n",
      "\n",
      "\n",
      "titanic_model version: 1\n",
      "\t Training context : Estimator\n",
      "\t Mean Absolute Error : 0.1787709497206704\n",
      "\t Accuracy : 0.8212290502793296\n",
      "\n",
      "\n",
      "diabetes_model version: 6\n",
      "\t Training context : Inline Training\n",
      "\t AUC : 0.8726180406985422\n",
      "\t Accuracy : 0.8856666666666667\n",
      "\n",
      "\n",
      "diabetes_model version: 5\n",
      "\t Training context : Inline Training\n",
      "\t AUC : 0.8751306035126125\n",
      "\t Accuracy : 0.889\n",
      "\n",
      "\n",
      "diabetes_model_automl version: 1\n",
      "\t Training context : Auto ML\n",
      "\t AUC : 0.9900438004392353\n",
      "\t Accuracy : 0.9534308211473566\n",
      "\n",
      "\n",
      "diabetes_model version: 4\n",
      "\t Training context : Inline Training\n",
      "\t AUC : 0.8753594706204287\n",
      "\t Accuracy : 0.8883333333333333\n",
      "\n",
      "\n",
      "diabetes_model version: 3\n",
      "\t Training context : Inline Training\n",
      "\t AUC : 0.8761057764067863\n",
      "\t Accuracy : 0.889\n",
      "\n",
      "\n",
      "diabetes_model version: 2\n",
      "\t Training context : Pipeline\n",
      "\n",
      "\n",
      "diabetes_model version: 1\n",
      "\t Training context : Estimator\n",
      "\t AUC : 0.8483377282451863\n",
      "\t Accuracy : 0.774\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# List registered models\n",
    "for model in Model.list(ws):\n",
    "    print(model.name, 'version:', model.version)\n",
    "    for tag_name in model.tags:\n",
    "        tag = model.tags[tag_name]\n",
    "        print ('\\t',tag_name, ':', tag)\n",
    "    for prop_name in model.properties:\n",
    "        prop = model.properties[prop_name]\n",
    "        print ('\\t',prop_name, ':', prop)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ne pas oublier à la fin de l'expérience!!\n",
    "(si votre travail à utilisé une instance de calcul)\n",
    "\n",
    "<img src='https://github.com/jtobelem-simplon/prepa-dp100/blob/master/images/down.png?raw=true'>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop toutes les instances de calcul\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute, ComputeInstance\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "for compute in ComputeTarget.list(ws):\n",
    "    if type(compute) is ComputeInstance and compute.get_status().state != 'Stopped':\n",
    "        print('try to stop compute', compute.name)\n",
    "        compute.stop(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vm-ds3-v2 {\n",
      "  \"errors\": [],\n",
      "  \"creationTime\": \"2020-05-27T10:12:38.674242+00:00\",\n",
      "  \"createdBy\": {\n",
      "    \"userId\": \"c88a830e-65d5-4e6d-a890-6d4497d2e6bd\",\n",
      "    \"userOrgId\": \"0840dabf-0881-4071-9392-f25b2728592f\"\n",
      "  },\n",
      "  \"modifiedTime\": \"2020-09-10T13:17:50.819127+00:00\",\n",
      "  \"state\": \"Stopped\",\n",
      "  \"vmSize\": \"STANDARD_DS3_V2\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# liste tous les compute pour vérifier qu'elles sont éteintes\n",
    "for compute in ComputeTarget.list(ws):\n",
    "    if type(compute) is ComputeInstance:\n",
    "        print(compute.name, compute.get_status())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ressources\n",
    "\n",
    "[api azure](https://docs.microsoft.com/en-us/python/api/azureml-core)\n",
    "\n",
    "[parcours d'apprentissage microsoft](https://docs.microsoft.com/fr-fr/learn/paths/build-ai-solutions-with-azure-ml-service/)\n",
    "\n",
    "[le repository microsoft](https://github.com/MicrosoftDocs/mslearn-aml-labs.git)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
