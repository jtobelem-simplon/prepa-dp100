{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://github.com/jtobelem-simplon/prepa-dp100/blob/master/images/top.png?raw=true'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration (Ã  lancer avant tous les notebooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.8.5'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version de python\n",
    "import platform\n",
    "platform.python_version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# packages in environment at /home/lab/anaconda3/envs/azure:\r\n",
      "#\r\n",
      "# Name                    Version                   Build  Channel\r\n",
      "_libgcc_mutex             0.1                        main  \r\n",
      "adal                      1.2.4                    pypi_0    pypi\r\n",
      "applicationinsights       0.11.9                   pypi_0    pypi\r\n",
      "async_generator           1.10                       py_0    conda-forge\r\n",
      "attrs                     20.2.0             pyh9f0ad1d_0    conda-forge\r\n",
      "azure-common              1.1.25                   pypi_0    pypi\r\n",
      "azure-core                1.8.1                    pypi_0    pypi\r\n",
      "azure-graphrbac           0.61.1                   pypi_0    pypi\r\n",
      "azure-identity            1.2.0                    pypi_0    pypi\r\n",
      "azure-mgmt-authorization  0.61.0                   pypi_0    pypi\r\n",
      "azure-mgmt-containerregistry 2.8.0                    pypi_0    pypi\r\n",
      "azure-mgmt-keyvault       2.2.0                    pypi_0    pypi\r\n",
      "azure-mgmt-resource       10.2.0                   pypi_0    pypi\r\n",
      "azure-mgmt-storage        11.2.0                   pypi_0    pypi\r\n",
      "azureml-automl-core       1.13.0                   pypi_0    pypi\r\n",
      "azureml-core              1.13.0                   pypi_0    pypi\r\n",
      "azureml-dataprep          2.0.8                    pypi_0    pypi\r\n",
      "azureml-dataprep-native   20.0.2                   pypi_0    pypi\r\n",
      "azureml-dataset-runtime   1.13.0                   pypi_0    pypi\r\n",
      "azureml-defaults          1.13.0                   pypi_0    pypi\r\n",
      "azureml-model-management-sdk 1.0.1b6.post1            pypi_0    pypi\r\n",
      "azureml-pipeline          1.13.0                   pypi_0    pypi\r\n",
      "azureml-pipeline-core     1.13.0                   pypi_0    pypi\r\n",
      "azureml-pipeline-steps    1.13.0                   pypi_0    pypi\r\n",
      "azureml-sdk               1.13.0                   pypi_0    pypi\r\n",
      "azureml-telemetry         1.13.0                   pypi_0    pypi\r\n",
      "azureml-train             1.13.0                   pypi_0    pypi\r\n",
      "azureml-train-automl-client 1.13.0.post1             pypi_0    pypi\r\n",
      "azureml-train-core        1.13.0                   pypi_0    pypi\r\n",
      "azureml-train-restclients-hyperdrive 1.13.0                   pypi_0    pypi\r\n",
      "azureml-widgets           1.13.0                   pypi_0    pypi\r\n",
      "backcall                  0.2.0              pyh9f0ad1d_0    conda-forge\r\n",
      "backports                 1.0                        py_2    conda-forge\r\n",
      "backports-tempfile        1.0                      pypi_0    pypi\r\n",
      "backports-weakref         1.0.post1                pypi_0    pypi\r\n",
      "backports.functools_lru_cache 1.6.1                      py_0    conda-forge\r\n",
      "bleach                    3.1.5              pyh9f0ad1d_0    conda-forge\r\n",
      "ca-certificates           2020.7.22                     0  \r\n",
      "certifi                   2020.6.20                py38_0  \r\n",
      "cffi                      1.14.2                   pypi_0    pypi\r\n",
      "chardet                   3.0.4                    pypi_0    pypi\r\n",
      "click                     7.1.2                    pypi_0    pypi\r\n",
      "cloudpickle               1.6.0                    pypi_0    pypi\r\n",
      "configparser              3.7.4                    pypi_0    pypi\r\n",
      "contextlib2               0.6.0.post1              pypi_0    pypi\r\n",
      "cryptography              3.1                      pypi_0    pypi\r\n",
      "cycler                    0.10.0                     py_2    conda-forge\r\n",
      "dbus                      1.13.16              hb2f20db_0  \r\n",
      "decorator                 4.4.2                      py_0    conda-forge\r\n",
      "defusedxml                0.6.0                      py_0    conda-forge\r\n",
      "dill                      0.3.2                    pypi_0    pypi\r\n",
      "distro                    1.5.0                    pypi_0    pypi\r\n",
      "docker                    4.3.1                    pypi_0    pypi\r\n",
      "dotnetcore2               2.1.14                   pypi_0    pypi\r\n",
      "entrypoints               0.3             py38h32f6830_1001    conda-forge\r\n",
      "expat                     2.2.9                he1b5a44_2    conda-forge\r\n",
      "flask                     1.0.3                    pypi_0    pypi\r\n",
      "fontconfig                2.13.1            he4413a7_1000    conda-forge\r\n",
      "freetype                  2.10.2               he06d7ca_0    conda-forge\r\n",
      "fusepy                    3.0.1                    pypi_0    pypi\r\n",
      "glib                      2.65.0               h3eb4bd4_0  \r\n",
      "gst-plugins-base          1.14.0               hbbd80ab_1  \r\n",
      "gstreamer                 1.14.0               hb31296c_0  \r\n",
      "gunicorn                  19.9.0                   pypi_0    pypi\r\n",
      "icu                       58.2              hf484d3e_1000    conda-forge\r\n",
      "idna                      2.10                     pypi_0    pypi\r\n",
      "importlib-metadata        1.7.0            py38h32f6830_0    conda-forge\r\n",
      "importlib_metadata        1.7.0                         0    conda-forge\r\n",
      "ipykernel                 5.3.4            py38h23f93f0_0    conda-forge\r\n",
      "ipython                   7.18.1           py38h1cdfbd6_0    conda-forge\r\n",
      "ipython_genutils          0.2.0                      py_1    conda-forge\r\n",
      "ipywidgets                7.5.1              pyh9f0ad1d_1    conda-forge\r\n",
      "isodate                   0.6.0                    pypi_0    pypi\r\n",
      "itsdangerous              1.1.0                    pypi_0    pypi\r\n",
      "jedi                      0.17.2           py38h32f6830_0    conda-forge\r\n",
      "jeepney                   0.4.3                    pypi_0    pypi\r\n",
      "jinja2                    2.11.2             pyh9f0ad1d_0    conda-forge\r\n",
      "jmespath                  0.10.0                   pypi_0    pypi\r\n",
      "joblib                    0.16.0                     py_0    conda-forge\r\n",
      "jpeg                      9d                   h516909a_0    conda-forge\r\n",
      "json-logging-py           0.2                      pypi_0    pypi\r\n",
      "jsonpickle                1.4.1                    pypi_0    pypi\r\n",
      "jsonschema                3.2.0            py38h32f6830_1    conda-forge\r\n",
      "jupyter                   1.0.0                    py38_7  \r\n",
      "jupyter_client            6.1.7                      py_0    conda-forge\r\n",
      "jupyter_console           6.2.0                      py_0    conda-forge\r\n",
      "jupyter_contrib_core      0.3.3                      py_2    conda-forge\r\n",
      "jupyter_contrib_nbextensions 0.5.1                    py38_0    conda-forge\r\n",
      "jupyter_core              4.6.3            py38h32f6830_1    conda-forge\r\n",
      "jupyter_highlight_selected_word 0.2.0                 py38_1000    conda-forge\r\n",
      "jupyter_latex_envs        1.4.6                 py38_1000    conda-forge\r\n",
      "jupyter_nbextensions_configurator 0.4.1            py38h32f6830_1    conda-forge\r\n",
      "jupyterlab_pygments       0.1.1              pyh9f0ad1d_0    conda-forge\r\n",
      "kiwisolver                1.2.0            py38hbf85e49_0    conda-forge\r\n",
      "lcms2                     2.11                 hbd6801e_0    conda-forge\r\n",
      "ld_impl_linux-64          2.33.1               h53a641e_7  \r\n",
      "liac-arff                 2.5.0                    pypi_0    pypi\r\n",
      "libblas                   3.8.0               17_openblas    conda-forge\r\n",
      "libcblas                  3.8.0               17_openblas    conda-forge\r\n",
      "libedit                   3.1.20191231         h14c3975_1  \r\n",
      "libffi                    3.3                  he6710b0_2  \r\n",
      "libgcc-ng                 9.1.0                hdf63c60_0  \r\n",
      "libgfortran-ng            7.5.0               hdf63c60_16    conda-forge\r\n",
      "liblapack                 3.8.0               17_openblas    conda-forge\r\n",
      "libopenblas               0.3.10          pthreads_hb3c22a3_4    conda-forge\r\n",
      "libpng                    1.6.37               hed695b0_2    conda-forge\r\n",
      "libsodium                 1.0.18               h516909a_0    conda-forge\r\n",
      "libstdcxx-ng              9.1.0                hdf63c60_0  \r\n",
      "libtiff                   4.1.0                hc7e4089_6    conda-forge\r\n",
      "libuuid                   2.32.1            h14c3975_1000    conda-forge\r\n",
      "libwebp-base              1.1.0                h516909a_3    conda-forge\r\n",
      "libxcb                    1.13              h14c3975_1002    conda-forge\r\n",
      "libxml2                   2.9.10               he19cac6_1  \r\n",
      "libxslt                   1.1.34               hc22bd24_0  \r\n",
      "lxml                      4.5.2            py38hbb43d70_0    conda-forge\r\n",
      "lz4-c                     1.9.2                he1b5a44_3    conda-forge\r\n",
      "markupsafe                1.1.1            py38h1e0a361_1    conda-forge\r\n",
      "matplotlib                3.3.2                         0    conda-forge\r\n",
      "matplotlib-base           3.3.2            py38h91b0d89_0    conda-forge\r\n",
      "mistune                   0.8.4           py38h1e0a361_1001    conda-forge\r\n",
      "msal                      1.5.0                    pypi_0    pypi\r\n",
      "msal-extensions           0.1.3                    pypi_0    pypi\r\n",
      "msrest                    0.6.19                   pypi_0    pypi\r\n",
      "msrestazure               0.6.4                    pypi_0    pypi\r\n",
      "nbclient                  0.5.0                      py_0    conda-forge\r\n",
      "nbconvert                 6.0.2            py38h32f6830_0    conda-forge\r\n",
      "nbformat                  5.0.7                      py_0    conda-forge\r\n",
      "ncurses                   6.2                  he6710b0_1  \r\n",
      "ndg-httpsclient           0.5.1                    pypi_0    pypi\r\n",
      "nest-asyncio              1.4.0                      py_0    conda-forge\r\n",
      "notebook                  6.0.3            py38h32f6830_1    conda-forge\r\n",
      "numpy                     1.19.1           py38hbc27379_2    conda-forge\r\n",
      "oauthlib                  3.1.0                    pypi_0    pypi\r\n",
      "olefile                   0.46                       py_0    conda-forge\r\n",
      "openssl                   1.1.1g               h7b6447c_0  \r\n",
      "packaging                 20.4               pyh9f0ad1d_0    conda-forge\r\n",
      "pandas                    1.1.2            py38h950e882_0    conda-forge\r\n",
      "pandoc                    2.10.1               h516909a_0    conda-forge\r\n",
      "pandocfilters             1.4.2                      py_1    conda-forge\r\n",
      "parso                     0.7.1              pyh9f0ad1d_0    conda-forge\r\n",
      "pathspec                  0.8.0                    pypi_0    pypi\r\n",
      "pcre                      8.44                 he1b5a44_0    conda-forge\r\n",
      "pexpect                   4.8.0            py38h32f6830_1    conda-forge\r\n",
      "pickleshare               0.7.5           py38h32f6830_1001    conda-forge\r\n",
      "pillow                    7.2.0            py38h9776b28_1    conda-forge\r\n",
      "pip                       20.2.3                     py_0    conda-forge\r\n",
      "portalocker               1.7.1                    pypi_0    pypi\r\n",
      "prometheus_client         0.8.0              pyh9f0ad1d_0    conda-forge\r\n",
      "prompt-toolkit            3.0.7                      py_0    conda-forge\r\n",
      "prompt_toolkit            3.0.7                         0    conda-forge\r\n",
      "pthread-stubs             0.4               h14c3975_1001    conda-forge\r\n",
      "ptyprocess                0.6.0                   py_1001    conda-forge\r\n",
      "pyarrow                   1.0.1                    pypi_0    pypi\r\n",
      "pyasn1                    0.4.8                    pypi_0    pypi\r\n",
      "pycparser                 2.20                     pypi_0    pypi\r\n",
      "pygments                  2.7.0                      py_0    conda-forge\r\n",
      "pyjwt                     1.7.1                    pypi_0    pypi\r\n",
      "pyopenssl                 19.1.0                   pypi_0    pypi\r\n",
      "pyparsing                 2.4.7              pyh9f0ad1d_0    conda-forge\r\n",
      "pyqt                      5.9.2            py38h05f1152_4  \r\n",
      "pyrsistent                0.17.3           py38h1e0a361_0    conda-forge\r\n",
      "python                    3.8.5                h7579374_1  \r\n",
      "python-dateutil           2.8.1                      py_0    conda-forge\r\n",
      "python_abi                3.8                      1_cp38    conda-forge\r\n",
      "pytz                      2020.1             pyh9f0ad1d_0    conda-forge\r\n",
      "pyyaml                    5.3.1            py38h1e0a361_0    conda-forge\r\n",
      "pyzmq                     19.0.2           py38ha71036d_0    conda-forge\r\n",
      "qt                        5.9.7                h5867ecd_1  \r\n",
      "qtconsole                 4.7.7              pyh9f0ad1d_0    conda-forge\r\n",
      "qtpy                      1.9.0                      py_0    conda-forge\r\n",
      "readline                  8.0                  h7b6447c_0  \r\n",
      "requests                  2.24.0                   pypi_0    pypi\r\n",
      "requests-oauthlib         1.3.0                    pypi_0    pypi\r\n",
      "ruamel-yaml               0.16.12                  pypi_0    pypi\r\n",
      "ruamel-yaml-clib          0.2.2                    pypi_0    pypi\r\n",
      "scikit-learn              0.23.2           py38hee58b96_0    conda-forge\r\n",
      "scipy                     1.5.2            py38h8c5af15_0    conda-forge\r\n",
      "secretstorage             3.1.2                    pypi_0    pypi\r\n",
      "send2trash                1.5.0                      py_0    conda-forge\r\n",
      "setuptools                49.6.0                   py38_0  \r\n",
      "sip                       4.19.13          py38he6710b0_0  \r\n",
      "six                       1.15.0             pyh9f0ad1d_0    conda-forge\r\n",
      "sqlite                    3.33.0               h62c20be_0  \r\n",
      "terminado                 0.8.3            py38h32f6830_1    conda-forge\r\n",
      "testpath                  0.4.4                      py_0    conda-forge\r\n",
      "threadpoolctl             2.1.0              pyh5ca1d4c_0    conda-forge\r\n",
      "tk                        8.6.10               hbc83047_0  \r\n",
      "tornado                   6.0.4            py38h1e0a361_1    conda-forge\r\n",
      "traitlets                 5.0.4                      py_0    conda-forge\r\n",
      "urllib3                   1.25.10                  pypi_0    pypi\r\n",
      "wcwidth                   0.2.5              pyh9f0ad1d_1    conda-forge\r\n",
      "webencodings              0.5.1                      py_1    conda-forge\r\n",
      "websocket-client          0.57.0                   pypi_0    pypi\r\n",
      "werkzeug                  0.16.1                   pypi_0    pypi\r\n",
      "wheel                     0.35.1                     py_0  \r\n",
      "widgetsnbextension        3.5.1            py38h32f6830_1    conda-forge\r\n",
      "xorg-libxau               1.0.9                h14c3975_0    conda-forge\r\n",
      "xorg-libxdmcp             1.1.3                h516909a_0    conda-forge\r\n",
      "xz                        5.2.5                h7b6447c_0  \r\n",
      "yaml                      0.2.5                h516909a_0    conda-forge\r\n",
      "zeromq                    4.3.2                he1b5a44_3    conda-forge\r\n",
      "zipp                      3.1.0                      py_0    conda-forge\r\n",
      "zlib                      1.2.11               h7b6447c_3  \r\n",
      "zstd                      1.4.5                h6597ccf_2    conda-forge\r\n"
     ]
    }
   ],
   "source": [
    "# la liste des packages installÃ©s\n",
    "!conda list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to use Azure ML 1.13.0\n"
     ]
    }
   ],
   "source": [
    "# version de la SDK azureml\n",
    "import azureml.core\n",
    "print(\"Ready to use Azure ML\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si le notebook est executÃ© en dehors d'Azure, il faut tÃ©lÃ©charger le fichier config.json depuis le portail https://portal.azure.com/, et le mettre dans le workspace qui contient le notebook.\n",
    "\n",
    "Si le notebook est exÃ©cutÃ© directement depuis le workspace Azure, le fichier de config devrait dÃ©jÃ  Ãªtre lÃ ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jt-dp100 loaded\n"
     ]
    }
   ],
   "source": [
    "# connexion au workspace\n",
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print(ws.name, \"loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avec les datastores\n",
    "\n",
    "In Azure ML, datastores are references to storage locations, such as Azure Storage blob containers. Every workspace has a default datastore - usually the Azure storage blob container that was created with the workspace. If you need to work with data that is stored in different locations, you can add custom datastores to your workspace and set any of them to be the default.\n",
    "\n",
    "[datastore dans la SDK](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.datastore.datastore?view=azure-ml-py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Datastores\n",
    "\n",
    "Run the following code to determine the datastores in your workspace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "azureml_globaldatasets - Default = False\n",
      "workspacefilestore - Default = False\n",
      "workspaceblobstore - Default = True\n"
     ]
    }
   ],
   "source": [
    "# Get the default datastore\n",
    "default_ds = ws.get_default_datastore()\n",
    "\n",
    "# Enumerate all datastores, indicating which is the default\n",
    "for ds_name in ws.datastores:\n",
    "    print(ds_name, \"- Default =\", ds_name == default_ds.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Data to a Datastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading an estimated of 1 files\n",
      "Uploading data/titanic/train.csv\n",
      "Uploaded data/titanic/train.csv, 1 files out of an estimated total of 1\n",
      "Uploaded 1 files\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_f14997add3e2492cafe6d061ff3b58f5"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_ds.upload_files(files=['data/titanic/train.csv'], # Upload the csv files in /data\n",
    "                       target_path='titanic-data/', # Put it in a folder path in the datastore\n",
    "                       overwrite=True, # Replace existing files of the same name\n",
    "                       show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$AZUREML_DATAREFERENCE_1a8c824b447c433cac6abf5cbe9e3489\n"
     ]
    }
   ],
   "source": [
    "data_ref = default_ds.path('titanic-data').as_download(path_on_compute='titanic-data')\n",
    "print(data_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour utiliser cette rÃ©fÃ©rence, il faut passer par un script..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## crÃ©ation d'un script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'script/3-titanic-files/titanic.csv'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, shutil\n",
    "\n",
    "# Create a folder for the experiment files\n",
    "script_folder_name = 'script/3-titanic-files'\n",
    "experiment_folder = './' + script_folder_name\n",
    "os.makedirs(script_folder_name, exist_ok=True)\n",
    "\n",
    "# Copy the data file into the experiment folder\n",
    "shutil.copy('data/titanic/train.csv', os.path.join(script_folder_name, \"titanic.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing script/3-titanic-files/titanic-data.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_folder_name/titanic-data.py\n",
    "\n",
    "from azureml.core import Run\n",
    "import pandas as pd\n",
    "\n",
    "# Get the args\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--data-folder', type=str, dest='data_folder', help='data folder reference')\n",
    "args = parser.parse_args()\n",
    "\n",
    "# Get the experiment run context\n",
    "run = Run.get_context()\n",
    "\n",
    "\n",
    "# load the titanic data from the data reference\n",
    "data_folder = args.data_folder\n",
    "print(\"Loading data from\", data_folder)\n",
    "# Load all files and concatenate their contents as a single dataframe\n",
    "all_files = os.listdir(data_folder)\n",
    "titanic = pd.concat((pd.read_csv(os.path.join(data_folder,csv_file)) for csv_file in all_files))\n",
    "\n",
    "\n",
    "# Count the rows and log the result\n",
    "row_count = (len(titanic))\n",
    "run.log('observations', row_count)\n",
    "print('Analyzing {} rows of data'.format(row_count))\n",
    "\n",
    "# Save a sample of the data and upload it to the experiment output\n",
    "titanic.sample(100).to_csv('sample.csv', index=False, header=True)\n",
    "run.upload_file(name = 'outputs/sample.csv', path_or_stream = 'sample.csv')\n",
    "\n",
    "# Complete the run\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - If 'script' has been provided here and a script file name has been specified in 'run_config', 'script' provided in ScriptRunConfig initialization will take precedence.\n",
      "WARNING - If 'arguments' has been provided here and arguments have been specified in 'run_config', 'arguments' provided in ScriptRunConfig initialization will take precedence.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1532996d4f6433e972a6766b48db2c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', 'â¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/titanic-data/runs/titanic-data_1600263529_0aa75e48?wsid=/subscriptions/9114a63e-9210-4e32-97ca-b7d9e8ac403d/resourcegroups/jt-dp100-ressources/workspaces/jt-dp100\", \"run_id\": \"titanic-data_1600263529_0aa75e48\", \"run_properties\": {\"run_id\": \"titanic-data_1600263529_0aa75e48\", \"created_utc\": \"2020-09-16T13:39:00.547347Z\", \"properties\": {\"_azureml.ComputeTargetType\": \"local\", \"ContentSnapshotId\": \"c3e8d0a9-b8fe-46c6-b1d5-99e033396013\", \"azureml.git.repository_uri\": \"https://github.com/jtobelem-simplon/prepa-dp100.git\", \"mlflow.source.git.repoURL\": \"https://github.com/jtobelem-simplon/prepa-dp100.git\", \"azureml.git.branch\": \"master\", \"mlflow.source.git.branch\": \"master\", \"azureml.git.commit\": \"ec3f4315d10480b95de0e7f372ca9be3530138bb\", \"mlflow.source.git.commit\": \"ec3f4315d10480b95de0e7f372ca9be3530138bb\", \"azureml.git.dirty\": \"True\"}, \"tags\": {}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": \"2020-09-16T13:39:21.284103Z\", \"status\": \"Completed\", \"log_files\": {\"azureml-logs/60_control_log.txt\": \"https://jtdp1009046233469.blob.core.windows.net/azureml/ExperimentRun/dcid.titanic-data_1600263529_0aa75e48/azureml-logs/60_control_log.txt?sv=2019-02-02&sr=b&sig=eghR62WMfkJ%2B8V7Xit4bZcli1xsfhw%2B%2BiqNnNbDEqtM%3D&st=2020-09-16T13%3A29%3A25Z&se=2020-09-16T21%3A39%3A25Z&sp=r\", \"azureml-logs/70_driver_log.txt\": \"https://jtdp1009046233469.blob.core.windows.net/azureml/ExperimentRun/dcid.titanic-data_1600263529_0aa75e48/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=bqIdNy5izYgdbMkbzGvP66jnLx3hYF4V0FV3Q0%2FFgeU%3D&st=2020-09-16T13%3A29%3A25Z&se=2020-09-16T21%3A39%3A25Z&sp=r\", \"logs/azureml/10_azureml.log\": \"https://jtdp1009046233469.blob.core.windows.net/azureml/ExperimentRun/dcid.titanic-data_1600263529_0aa75e48/logs/azureml/10_azureml.log?sv=2019-02-02&sr=b&sig=0Kn1qFGL857ZLbxTxu7S%2BHC5srV7ScEhCBocAKAqRW4%3D&st=2020-09-16T13%3A29%3A12Z&se=2020-09-16T21%3A39%3A12Z&sp=r\"}, \"log_groups\": [[\"logs/azureml/10_azureml.log\"], [\"azureml-logs/60_control_log.txt\"], [\"azureml-logs/70_driver_log.txt\"]], \"run_duration\": \"0:00:20\"}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [{\"name\": \"observations\", \"run_id\": \"titanic-data_1600263529_0aa75e48\", \"categories\": [0], \"series\": [{\"data\": [891]}]}], \"run_logs\": \"[2020-09-16T13:39:07.230769] Entering context manager injector.\\n[context_manager_injector.py] Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'DataStoreCopy:context_managers.DataStores', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError'], invocation=['titanic-data.py', '--data-folder', 'titanic-data/titanic-data'])\\nStarting the daemon thread to refresh tokens in background for process with pid = 10\\nAcquired lockfile /tmp/titanic-data_1600263529_0aa75e48-datastore.lock to downloading input data references\\nDownloading titanic-data/train.csv\\nDownloaded titanic-data/train.csv, 1 files out of an estimated total of 1\\nEntering Run History Context Manager.\\nCurrent directory:  /azureml-run\\nPreparing to call script [ titanic-data.py ] with arguments: ['--data-folder', 'titanic-data/titanic-data']\\nAfter variable expansion, calling script [ titanic-data.py ] with arguments: ['--data-folder', 'titanic-data/titanic-data']\\n\\nScript type = None\\nLoading data from titanic-data/titanic-data\\nAnalyzing 891 rows of data\\nStarting the daemon thread to refresh tokens in background for process with pid = 10\\n\\n\\nThe experiment completed successfully. Finalizing run...\\nLogging experiment finalizing status in history service.\\n[2020-09-16T13:39:13.608159] TimeoutHandler __init__\\n[2020-09-16T13:39:13.608211] TimeoutHandler __enter__\\nCleaning up all outstanding Run operations, waiting 300.0 seconds\\n2 items cleaning up...\\nCleanup took 0.5088088512420654 seconds\\n[2020-09-16T13:39:14.616756] TimeoutHandler __exit__\\n[2020-09-16T13:39:14.925246] TimeoutHandler __init__\\n[2020-09-16T13:39:14.925281] TimeoutHandler __enter__\\n[2020-09-16T13:39:14.925522] TimeoutHandler __exit__\\n\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.13.0\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'titanic-data_1600263529_0aa75e48',\n",
       " 'target': 'local',\n",
       " 'status': 'Finalizing',\n",
       " 'startTimeUtc': '2020-09-16T13:39:04.065038Z',\n",
       " 'properties': {'_azureml.ComputeTargetType': 'local',\n",
       "  'ContentSnapshotId': 'c3e8d0a9-b8fe-46c6-b1d5-99e033396013',\n",
       "  'azureml.git.repository_uri': 'https://github.com/jtobelem-simplon/prepa-dp100.git',\n",
       "  'mlflow.source.git.repoURL': 'https://github.com/jtobelem-simplon/prepa-dp100.git',\n",
       "  'azureml.git.branch': 'master',\n",
       "  'mlflow.source.git.branch': 'master',\n",
       "  'azureml.git.commit': 'ec3f4315d10480b95de0e7f372ca9be3530138bb',\n",
       "  'mlflow.source.git.commit': 'ec3f4315d10480b95de0e7f372ca9be3530138bb',\n",
       "  'azureml.git.dirty': 'True'},\n",
       " 'inputDatasets': [],\n",
       " 'outputDatasets': [],\n",
       " 'runDefinition': {'script': 'titanic-data.py',\n",
       "  'scriptType': None,\n",
       "  'useAbsolutePath': False,\n",
       "  'arguments': ['--data-folder',\n",
       "   '$AZUREML_DATAREFERENCE_1a8c824b447c433cac6abf5cbe9e3489'],\n",
       "  'sourceDirectoryDataStore': None,\n",
       "  'framework': 'Python',\n",
       "  'communicator': 'None',\n",
       "  'target': 'local',\n",
       "  'dataReferences': {'1a8c824b447c433cac6abf5cbe9e3489': {'dataStoreName': 'workspaceblobstore',\n",
       "    'mode': 'Download',\n",
       "    'pathOnDataStore': 'titanic-data',\n",
       "    'pathOnCompute': 'titanic-data',\n",
       "    'overwrite': False}},\n",
       "  'data': {},\n",
       "  'outputData': {},\n",
       "  'jobName': None,\n",
       "  'maxRunDurationSeconds': None,\n",
       "  'nodeCount': 1,\n",
       "  'environment': {'name': 'Experiment titanic-data Environment',\n",
       "   'version': 'Autosave_2020-09-14T16:00:32Z_c26e9f42',\n",
       "   'python': {'interpreterPath': 'python',\n",
       "    'userManagedDependencies': False,\n",
       "    'condaDependencies': {'channels': ['anaconda', 'conda-forge'],\n",
       "     'dependencies': ['python=3.6.2',\n",
       "      {'pip': ['azureml-defaults',\n",
       "        'scikit-learn==0.20.3',\n",
       "        'scipy==1.2.1',\n",
       "        'joblib==0.13.2']}],\n",
       "     'name': 'azureml_ba9520bf386d662001eeb9523395794e'},\n",
       "    'baseCondaEnvironment': None},\n",
       "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'docker': {'baseImage': 'mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20200423.v1',\n",
       "    'platform': {'os': 'Linux', 'architecture': 'amd64'},\n",
       "    'baseDockerfile': None,\n",
       "    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n",
       "    'enabled': True,\n",
       "    'arguments': []},\n",
       "   'spark': {'repositories': [], 'packages': [], 'precachePackages': False},\n",
       "   'inferencingStackVersion': None},\n",
       "  'history': {'outputCollection': True,\n",
       "   'directoriesToWatch': ['logs'],\n",
       "   'enableMLflowTracking': True,\n",
       "   'snapshotProject': True},\n",
       "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'parallelTask': {'maxRetriesPerWorker': 0,\n",
       "   'workerCountPerNode': 1,\n",
       "   'terminalExitCodes': None,\n",
       "   'configuration': {}},\n",
       "  'amlCompute': {'name': None,\n",
       "   'vmSize': None,\n",
       "   'retainCluster': False,\n",
       "   'clusterMaxNodeCount': 1},\n",
       "  'aiSuperComputer': {'instanceType': None,\n",
       "   'frameworkImage': None,\n",
       "   'imageVersion': None,\n",
       "   'location': None},\n",
       "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
       "  'mpi': {'processCountPerNode': 1},\n",
       "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
       "  'containerInstance': {'region': None, 'cpuCores': 2, 'memoryGb': 3.5},\n",
       "  'exposedPorts': None,\n",
       "  'docker': {'useDocker': True,\n",
       "   'sharedVolumes': True,\n",
       "   'shmSize': '2g',\n",
       "   'arguments': []},\n",
       "  'cmk8sCompute': {'configuration': {}},\n",
       "  'cmAksCompute': {'configuration': {}}},\n",
       " 'logFiles': {'azureml-logs/60_control_log.txt': 'https://jtdp1009046233469.blob.core.windows.net/azureml/ExperimentRun/dcid.titanic-data_1600263529_0aa75e48/azureml-logs/60_control_log.txt?sv=2019-02-02&sr=b&sig=MC6vvJHwi9HWM%2FHuPn6rRIWAlm8vStyU9yplsDtr69o%3D&st=2020-09-16T13%3A29%3A14Z&se=2020-09-16T21%3A39%3A14Z&sp=r',\n",
       "  'azureml-logs/70_driver_log.txt': 'https://jtdp1009046233469.blob.core.windows.net/azureml/ExperimentRun/dcid.titanic-data_1600263529_0aa75e48/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=SfYingKC9cGXrIARszQl8yrwQrSbYXiJOFU4ydBVN2o%3D&st=2020-09-16T13%3A29%3A14Z&se=2020-09-16T21%3A39%3A14Z&sp=r',\n",
       "  'logs/azureml/10_azureml.log': 'https://jtdp1009046233469.blob.core.windows.net/azureml/ExperimentRun/dcid.titanic-data_1600263529_0aa75e48/logs/azureml/10_azureml.log?sv=2019-02-02&sr=b&sig=0Kn1qFGL857ZLbxTxu7S%2BHC5srV7ScEhCBocAKAqRW4%3D&st=2020-09-16T13%3A29%3A12Z&se=2020-09-16T21%3A39%3A12Z&sp=r'}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.train.sklearn import SKLearn\n",
    "from azureml.core import Experiment\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "# Set up the parameters\n",
    "script_params = {\n",
    "    '--data-folder': data_ref # data reference to download files from datastore\n",
    "}\n",
    "\n",
    "\n",
    "# Create an estimator\n",
    "estimator = SKLearn(source_directory=experiment_folder,\n",
    "                    entry_script='titanic-data.py',\n",
    "                    script_params=script_params,\n",
    "                    compute_target = 'local'\n",
    "                   )\n",
    "\n",
    "# Create an experiment\n",
    "experiment_name = 'titanic-data'\n",
    "experiment = Experiment(workspace = ws, name = experiment_name)\n",
    "\n",
    "# Run the experiment\n",
    "run = experiment.submit(config=estimator)\n",
    "# Show the run details while running\n",
    "RunDetails(run).show()\n",
    "run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avec les datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading an estimated of 1 files\n",
      "Uploading ./data/titanic/train.csv\n",
      "Uploaded ./data/titanic/train.csv, 1 files out of an estimated total of 1\n",
      "Uploaded 1 files\n",
      "Dataset registered.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Dataset\n",
    "\n",
    "default_ds = ws.get_default_datastore()\n",
    "\n",
    "if 'titanic train dataset' not in ws.datasets:\n",
    "    default_ds.upload_files(files=['./data/titanic/train.csv'], # Upload the titanic csv files in /data\n",
    "                        target_path='titanic-data/', # Put it in a folder path in the datastore\n",
    "                        overwrite=True, # Replace existing files of the same name\n",
    "                        show_progress=True)\n",
    "\n",
    "    #Create a tabular dataset from the path on the datastore (this may take a short while)\n",
    "    tab_data_set = Dataset.Tabular.from_delimited_files(path=(default_ds, 'titanic-data/train.csv'))\n",
    "\n",
    "    # Register the tabular dataset\n",
    "    try:\n",
    "        tab_data_set = tab_data_set.register(workspace=ws, \n",
    "                                name='titanic train dataset',\n",
    "                                description='titanic training data',\n",
    "                                tags = {'format':'CSV'},\n",
    "                                create_new_version=True)\n",
    "        print('Dataset registered.')\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "else:\n",
    "    print('Dataset already registered.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading an estimated of 1 files\n",
      "Uploading ./data/titanic/test.csv\n",
      "Uploaded ./data/titanic/test.csv, 1 files out of an estimated total of 1\n",
      "Uploaded 1 files\n",
      "Dataset registered.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Dataset\n",
    "\n",
    "default_ds = ws.get_default_datastore()\n",
    "\n",
    "if 'titanic test dataset' not in ws.datasets:\n",
    "    default_ds.upload_files(files=['./data/titanic/test.csv'], # Upload the titanic csv files in /data\n",
    "                        target_path='titanic-data/', # Put it in a folder path in the datastore\n",
    "                        overwrite=True, # Replace existing files of the same name\n",
    "                        show_progress=True)\n",
    "\n",
    "    #Create a tabular dataset from the path on the datastore (this may take a short while)\n",
    "    tab_data_set = Dataset.Tabular.from_delimited_files(path=(default_ds, 'titanic-data/test.csv'))\n",
    "\n",
    "    # Register the tabular dataset\n",
    "    try:\n",
    "        tab_data_set = tab_data_set.register(workspace=ws, \n",
    "                                name='titanic test dataset',\n",
    "                                description='titanic testing data',\n",
    "                                tags = {'format':'CSV'},\n",
    "                                create_new_version=True)\n",
    "        print('Dataset registered.')\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "else:\n",
    "    print('Dataset already registered.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "titanic_ds = ws.datasets.get(\"titanic train dataset\")\n",
    "titanic_ds.to_pandas_dataframe().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lab/anaconda3/envs/azure/lib/python3.8/site-packages/azureml/dataprep/api/_dataframereader.py:234: UserWarning: Using alternate reader. Inconsistent or mixed schemas detected across partitions: partition had different number of columns. The first partition has 11 columns. Found partition has 12 columns.\n",
      "First partition columns (ordered): ['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\n",
      "Found Partition has columns (ordered): ['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked', 'Column12']\n",
      "  warnings.warn('Using alternate reader. ' + reason)\n",
      "/home/lab/anaconda3/envs/azure/lib/python3.8/site-packages/azureml/dataprep/api/_dataframereader.py:178: UserWarning: Please install pyarrow>=0.16.0 for improved performance of to_pandas_dataframe. You can ensure the correct version is installed by running: pip install pyarrow>=0.12.0 --upgrade\n",
      "  warnings.warn('Please install pyarrow>=0.16.0 for improved performance of to_pandas_dataframe. '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Column12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>None</td>\n",
       "      <td>Q</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>None</td>\n",
       "      <td>Q</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked Column12  \n",
       "0  34.5    0.0      0   330911   7.8292  None        Q     None  \n",
       "1    47    1.0      0   363272   7.0000  None        S     None  \n",
       "2    62    0.0      0   240276   9.6875  None        Q     None  \n",
       "3    27    0.0      0   315154   8.6625  None        S     None  \n",
       "4    22    1.0      1  3101298  12.2875  None        S     None  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ne pas oublier Ã  la fin de l'expÃ©rience!!\n",
    "(si votre travail Ã  utilisÃ© une instance de calcul)\n",
    "\n",
    "<img src='https://github.com/jtobelem-simplon/prepa-dp100/blob/master/images/down.png?raw=true'>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ne pas oublier Ã  la fin de l'expÃ©rience!!\n",
    "(si votre travail Ã  utilisÃ© une instance de calcul)\n",
    "\n",
    "<img src='https://github.com/jtobelem-simplon/prepa-dp100/blob/master/images/down.png?raw=true'>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop toutes les instances de calcul\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute, ComputeInstance\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "for compute in ComputeTarget.list(ws):\n",
    "    if type(compute) is ComputeInstance and compute.get_status().state != 'Stopped':\n",
    "        print('try to stop compute', compute.name)\n",
    "        compute.stop(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# liste tous les compute pour vÃ©rifier qu'elles sont Ã©teintes\n",
    "for compute in ComputeTarget.list(ws):\n",
    "    if type(compute) is ComputeInstance:\n",
    "        print(compute.name, compute.get_status())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ressources\n",
    "\n",
    "[api azure](https://docs.microsoft.com/en-us/python/api/azureml-core)\n",
    "\n",
    "[parcours d'apprentissage microsoft](https://docs.microsoft.com/fr-fr/learn/paths/build-ai-solutions-with-azure-ml-service/)\n",
    "\n",
    "[le repository microsoft](https://github.com/MicrosoftDocs/mslearn-aml-labs.git)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}