{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://github.com/jtobelem-simplon/prepa-dp100/blob/master/images/top.png?raw=true'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration (à lancer avant tous les notebooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.8.5'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version de python\n",
    "import platform\n",
    "platform.python_version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# packages in environment at /home/lab/anaconda3/envs/azure:\r\n",
      "#\r\n",
      "# Name                    Version                   Build  Channel\r\n",
      "_libgcc_mutex             0.1                        main  \r\n",
      "adal                      1.2.4                    pypi_0    pypi\r\n",
      "applicationinsights       0.11.9                   pypi_0    pypi\r\n",
      "async_generator           1.10                       py_0    conda-forge\r\n",
      "attrs                     20.2.0             pyh9f0ad1d_0    conda-forge\r\n",
      "azure-common              1.1.25                   pypi_0    pypi\r\n",
      "azure-core                1.8.1                    pypi_0    pypi\r\n",
      "azure-graphrbac           0.61.1                   pypi_0    pypi\r\n",
      "azure-identity            1.2.0                    pypi_0    pypi\r\n",
      "azure-mgmt-authorization  0.61.0                   pypi_0    pypi\r\n",
      "azure-mgmt-containerregistry 2.8.0                    pypi_0    pypi\r\n",
      "azure-mgmt-keyvault       2.2.0                    pypi_0    pypi\r\n",
      "azure-mgmt-resource       10.2.0                   pypi_0    pypi\r\n",
      "azure-mgmt-storage        11.2.0                   pypi_0    pypi\r\n",
      "azureml-automl-core       1.13.0                   pypi_0    pypi\r\n",
      "azureml-core              1.13.0                   pypi_0    pypi\r\n",
      "azureml-dataprep          2.0.8                    pypi_0    pypi\r\n",
      "azureml-dataprep-native   20.0.2                   pypi_0    pypi\r\n",
      "azureml-dataset-runtime   1.13.0                   pypi_0    pypi\r\n",
      "azureml-pipeline          1.13.0                   pypi_0    pypi\r\n",
      "azureml-pipeline-core     1.13.0                   pypi_0    pypi\r\n",
      "azureml-pipeline-steps    1.13.0                   pypi_0    pypi\r\n",
      "azureml-sdk               1.13.0                   pypi_0    pypi\r\n",
      "azureml-telemetry         1.13.0                   pypi_0    pypi\r\n",
      "azureml-train             1.13.0                   pypi_0    pypi\r\n",
      "azureml-train-automl-client 1.13.0.post1             pypi_0    pypi\r\n",
      "azureml-train-core        1.13.0                   pypi_0    pypi\r\n",
      "azureml-train-restclients-hyperdrive 1.13.0                   pypi_0    pypi\r\n",
      "azureml-widgets           1.13.0                   pypi_0    pypi\r\n",
      "backcall                  0.2.0              pyh9f0ad1d_0    conda-forge\r\n",
      "backports                 1.0                        py_2    conda-forge\r\n",
      "backports-tempfile        1.0                      pypi_0    pypi\r\n",
      "backports-weakref         1.0.post1                pypi_0    pypi\r\n",
      "backports.functools_lru_cache 1.6.1                      py_0    conda-forge\r\n",
      "bleach                    3.1.5              pyh9f0ad1d_0    conda-forge\r\n",
      "ca-certificates           2020.7.22                     0  \r\n",
      "certifi                   2020.6.20                py38_0  \r\n",
      "cffi                      1.14.2                   pypi_0    pypi\r\n",
      "chardet                   3.0.4                    pypi_0    pypi\r\n",
      "cloudpickle               1.6.0                    pypi_0    pypi\r\n",
      "contextlib2               0.6.0.post1              pypi_0    pypi\r\n",
      "cryptography              3.1                      pypi_0    pypi\r\n",
      "cycler                    0.10.0                     py_2    conda-forge\r\n",
      "dbus                      1.13.16              hb2f20db_0  \r\n",
      "decorator                 4.4.2                      py_0    conda-forge\r\n",
      "defusedxml                0.6.0                      py_0    conda-forge\r\n",
      "distro                    1.5.0                    pypi_0    pypi\r\n",
      "docker                    4.3.1                    pypi_0    pypi\r\n",
      "dotnetcore2               2.1.14                   pypi_0    pypi\r\n",
      "entrypoints               0.3             py38h32f6830_1001    conda-forge\r\n",
      "expat                     2.2.9                he1b5a44_2    conda-forge\r\n",
      "fontconfig                2.13.1            he4413a7_1000    conda-forge\r\n",
      "freetype                  2.10.2               he06d7ca_0    conda-forge\r\n",
      "fusepy                    3.0.1                    pypi_0    pypi\r\n",
      "glib                      2.65.0               h3eb4bd4_0  \r\n",
      "gst-plugins-base          1.14.0               hbbd80ab_1  \r\n",
      "gstreamer                 1.14.0               hb31296c_0  \r\n",
      "icu                       58.2              hf484d3e_1000    conda-forge\r\n",
      "idna                      2.10                     pypi_0    pypi\r\n",
      "importlib-metadata        1.7.0            py38h32f6830_0    conda-forge\r\n",
      "importlib_metadata        1.7.0                         0    conda-forge\r\n",
      "ipykernel                 5.3.4            py38h23f93f0_0    conda-forge\r\n",
      "ipython                   7.18.1           py38h1cdfbd6_0    conda-forge\r\n",
      "ipython_genutils          0.2.0                      py_1    conda-forge\r\n",
      "ipywidgets                7.5.1              pyh9f0ad1d_1    conda-forge\r\n",
      "isodate                   0.6.0                    pypi_0    pypi\r\n",
      "jedi                      0.17.2           py38h32f6830_0    conda-forge\r\n",
      "jeepney                   0.4.3                    pypi_0    pypi\r\n",
      "jinja2                    2.11.2             pyh9f0ad1d_0    conda-forge\r\n",
      "jmespath                  0.10.0                   pypi_0    pypi\r\n",
      "joblib                    0.16.0                     py_0    conda-forge\r\n",
      "jpeg                      9d                   h516909a_0    conda-forge\r\n",
      "jsonpickle                1.4.1                    pypi_0    pypi\r\n",
      "jsonschema                3.2.0            py38h32f6830_1    conda-forge\r\n",
      "jupyter                   1.0.0                    py38_7  \r\n",
      "jupyter_client            6.1.7                      py_0    conda-forge\r\n",
      "jupyter_console           6.2.0                      py_0    conda-forge\r\n",
      "jupyter_contrib_core      0.3.3                      py_2    conda-forge\r\n",
      "jupyter_contrib_nbextensions 0.5.1                    py38_0    conda-forge\r\n",
      "jupyter_core              4.6.3            py38h32f6830_1    conda-forge\r\n",
      "jupyter_highlight_selected_word 0.2.0                 py38_1000    conda-forge\r\n",
      "jupyter_latex_envs        1.4.6                 py38_1000    conda-forge\r\n",
      "jupyter_nbextensions_configurator 0.4.1            py38h32f6830_1    conda-forge\r\n",
      "jupyterlab_pygments       0.1.1              pyh9f0ad1d_0    conda-forge\r\n",
      "kiwisolver                1.2.0            py38hbf85e49_0    conda-forge\r\n",
      "lcms2                     2.11                 hbd6801e_0    conda-forge\r\n",
      "ld_impl_linux-64          2.33.1               h53a641e_7  \r\n",
      "libblas                   3.8.0               17_openblas    conda-forge\r\n",
      "libcblas                  3.8.0               17_openblas    conda-forge\r\n",
      "libedit                   3.1.20191231         h14c3975_1  \r\n",
      "libffi                    3.3                  he6710b0_2  \r\n",
      "libgcc-ng                 9.1.0                hdf63c60_0  \r\n",
      "libgfortran-ng            7.5.0               hdf63c60_16    conda-forge\r\n",
      "liblapack                 3.8.0               17_openblas    conda-forge\r\n",
      "libopenblas               0.3.10          pthreads_hb3c22a3_4    conda-forge\r\n",
      "libpng                    1.6.37               hed695b0_2    conda-forge\r\n",
      "libsodium                 1.0.18               h516909a_0    conda-forge\r\n",
      "libstdcxx-ng              9.1.0                hdf63c60_0  \r\n",
      "libtiff                   4.1.0                hc7e4089_6    conda-forge\r\n",
      "libuuid                   2.32.1            h14c3975_1000    conda-forge\r\n",
      "libwebp-base              1.1.0                h516909a_3    conda-forge\r\n",
      "libxcb                    1.13              h14c3975_1002    conda-forge\r\n",
      "libxml2                   2.9.10               he19cac6_1  \r\n",
      "libxslt                   1.1.34               hc22bd24_0  \r\n",
      "lxml                      4.5.2            py38hbb43d70_0    conda-forge\r\n",
      "lz4-c                     1.9.2                he1b5a44_3    conda-forge\r\n",
      "markupsafe                1.1.1            py38h1e0a361_1    conda-forge\r\n",
      "matplotlib                3.3.2                         0    conda-forge\r\n",
      "matplotlib-base           3.3.2            py38h91b0d89_0    conda-forge\r\n",
      "mistune                   0.8.4           py38h1e0a361_1001    conda-forge\r\n",
      "msal                      1.5.0                    pypi_0    pypi\r\n",
      "msal-extensions           0.1.3                    pypi_0    pypi\r\n",
      "msrest                    0.6.19                   pypi_0    pypi\r\n",
      "msrestazure               0.6.4                    pypi_0    pypi\r\n",
      "nbclient                  0.5.0                      py_0    conda-forge\r\n",
      "nbconvert                 6.0.2            py38h32f6830_0    conda-forge\r\n",
      "nbformat                  5.0.7                      py_0    conda-forge\r\n",
      "ncurses                   6.2                  he6710b0_1  \r\n",
      "ndg-httpsclient           0.5.1                    pypi_0    pypi\r\n",
      "nest-asyncio              1.4.0                      py_0    conda-forge\r\n",
      "notebook                  6.0.3            py38h32f6830_1    conda-forge\r\n",
      "numpy                     1.19.1           py38hbc27379_2    conda-forge\r\n",
      "oauthlib                  3.1.0                    pypi_0    pypi\r\n",
      "olefile                   0.46                       py_0    conda-forge\r\n",
      "openssl                   1.1.1g               h7b6447c_0  \r\n",
      "packaging                 20.4               pyh9f0ad1d_0    conda-forge\r\n",
      "pandas                    1.1.2            py38h950e882_0    conda-forge\r\n",
      "pandoc                    2.10.1               h516909a_0    conda-forge\r\n",
      "pandocfilters             1.4.2                      py_1    conda-forge\r\n",
      "parso                     0.7.1              pyh9f0ad1d_0    conda-forge\r\n",
      "pathspec                  0.8.0                    pypi_0    pypi\r\n",
      "pcre                      8.44                 he1b5a44_0    conda-forge\r\n",
      "pexpect                   4.8.0            py38h32f6830_1    conda-forge\r\n",
      "pickleshare               0.7.5           py38h32f6830_1001    conda-forge\r\n",
      "pillow                    7.2.0            py38h9776b28_1    conda-forge\r\n",
      "pip                       20.2.3                     py_0    conda-forge\r\n",
      "portalocker               1.7.1                    pypi_0    pypi\r\n",
      "prometheus_client         0.8.0              pyh9f0ad1d_0    conda-forge\r\n",
      "prompt-toolkit            3.0.7                      py_0    conda-forge\r\n",
      "prompt_toolkit            3.0.7                         0    conda-forge\r\n",
      "pthread-stubs             0.4               h14c3975_1001    conda-forge\r\n",
      "ptyprocess                0.6.0                   py_1001    conda-forge\r\n",
      "pyarrow                   1.0.1                    pypi_0    pypi\r\n",
      "pyasn1                    0.4.8                    pypi_0    pypi\r\n",
      "pycparser                 2.20                     pypi_0    pypi\r\n",
      "pygments                  2.7.0                      py_0    conda-forge\r\n",
      "pyjwt                     1.7.1                    pypi_0    pypi\r\n",
      "pyopenssl                 19.1.0                   pypi_0    pypi\r\n",
      "pyparsing                 2.4.7              pyh9f0ad1d_0    conda-forge\r\n",
      "pyqt                      5.9.2            py38h05f1152_4  \r\n",
      "pyrsistent                0.17.3           py38h1e0a361_0    conda-forge\r\n",
      "python                    3.8.5                h7579374_1  \r\n",
      "python-dateutil           2.8.1                      py_0    conda-forge\r\n",
      "python_abi                3.8                      1_cp38    conda-forge\r\n",
      "pytz                      2020.1             pyh9f0ad1d_0    conda-forge\r\n",
      "pyyaml                    5.3.1            py38h1e0a361_0    conda-forge\r\n",
      "pyzmq                     19.0.2           py38ha71036d_0    conda-forge\r\n",
      "qt                        5.9.7                h5867ecd_1  \r\n",
      "qtconsole                 4.7.7              pyh9f0ad1d_0    conda-forge\r\n",
      "qtpy                      1.9.0                      py_0    conda-forge\r\n",
      "readline                  8.0                  h7b6447c_0  \r\n",
      "requests                  2.24.0                   pypi_0    pypi\r\n",
      "requests-oauthlib         1.3.0                    pypi_0    pypi\r\n",
      "ruamel-yaml               0.16.12                  pypi_0    pypi\r\n",
      "ruamel-yaml-clib          0.2.2                    pypi_0    pypi\r\n",
      "scikit-learn              0.23.2           py38hee58b96_0    conda-forge\r\n",
      "scipy                     1.5.2            py38h8c5af15_0    conda-forge\r\n",
      "secretstorage             3.1.2                    pypi_0    pypi\r\n",
      "send2trash                1.5.0                      py_0    conda-forge\r\n",
      "setuptools                49.6.0                   py38_0  \r\n",
      "sip                       4.19.13          py38he6710b0_0  \r\n",
      "six                       1.15.0             pyh9f0ad1d_0    conda-forge\r\n",
      "sqlite                    3.33.0               h62c20be_0  \r\n",
      "terminado                 0.8.3            py38h32f6830_1    conda-forge\r\n",
      "testpath                  0.4.4                      py_0    conda-forge\r\n",
      "threadpoolctl             2.1.0              pyh5ca1d4c_0    conda-forge\r\n",
      "tk                        8.6.10               hbc83047_0  \r\n",
      "tornado                   6.0.4            py38h1e0a361_1    conda-forge\r\n",
      "traitlets                 5.0.4                      py_0    conda-forge\r\n",
      "urllib3                   1.25.10                  pypi_0    pypi\r\n",
      "wcwidth                   0.2.5              pyh9f0ad1d_1    conda-forge\r\n",
      "webencodings              0.5.1                      py_1    conda-forge\r\n",
      "websocket-client          0.57.0                   pypi_0    pypi\r\n",
      "wheel                     0.35.1                     py_0  \r\n",
      "widgetsnbextension        3.5.1            py38h32f6830_1    conda-forge\r\n",
      "xorg-libxau               1.0.9                h14c3975_0    conda-forge\r\n",
      "xorg-libxdmcp             1.1.3                h516909a_0    conda-forge\r\n",
      "xz                        5.2.5                h7b6447c_0  \r\n",
      "yaml                      0.2.5                h516909a_0    conda-forge\r\n",
      "zeromq                    4.3.2                he1b5a44_3    conda-forge\r\n",
      "zipp                      3.1.0                      py_0    conda-forge\r\n",
      "zlib                      1.2.11               h7b6447c_3  \r\n",
      "zstd                      1.4.5                h6597ccf_2    conda-forge\r\n"
     ]
    }
   ],
   "source": [
    "# la liste des packages installés\n",
    "!conda list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to use Azure ML 1.13.0\n"
     ]
    }
   ],
   "source": [
    "# version de la SDK azureml\n",
    "import azureml.core\n",
    "print(\"Ready to use Azure ML\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si le notebook est executé en dehors d'Azure, il faut télécharger le fichier config.json depuis le portail https://portal.azure.com/, et le mettre dans le workspace qui contient le notebook.\n",
    "\n",
    "Si le notebook est exécuté directement depuis le workspace Azure, le fichier de config devrait déjà être là."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jt-dp100 loaded\n"
     ]
    }
   ],
   "source": [
    "# connexion au workspace\n",
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print(ws.name, \"loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avec les datastores\n",
    "\n",
    "In Azure ML, datastores are references to storage locations, such as Azure Storage blob containers. Every workspace has a default datastore - usually the Azure storage blob container that was created with the workspace. If you need to work with data that is stored in different locations, you can add custom datastores to your workspace and set any of them to be the default.\n",
    "\n",
    "[datastore dans la SDK](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.datastore.datastore?view=azure-ml-py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Datastores\n",
    "\n",
    "Run the following code to determine the datastores in your workspace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workspacefilestore - Default = False\n",
      "workspaceblobstore - Default = True\n"
     ]
    }
   ],
   "source": [
    "# Get the default datastore\n",
    "default_ds = ws.get_default_datastore()\n",
    "\n",
    "# Enumerate all datastores, indicating which is the default\n",
    "for ds_name in ws.datastores:\n",
    "    print(ds_name, \"- Default =\", ds_name == default_ds.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Data to a Datastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading an estimated of 1 files\n",
      "Uploading data/titanic/train.csv\n",
      "Uploaded data/titanic/train.csv, 1 files out of an estimated total of 1\n",
      "Uploaded 1 files\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_bc04233daeba4d6cac061e38f20a2a6f"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_ds.upload_files(files=['data/titanic/train.csv'], # Upload the csv files in /data\n",
    "                       target_path='titanic-data/', # Put it in a folder path in the datastore\n",
    "                       overwrite=True, # Replace existing files of the same name\n",
    "                       show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$AZUREML_DATAREFERENCE_2cd23afaad104ac9b705b96681855f68\n"
     ]
    }
   ],
   "source": [
    "data_ref = default_ds.path('titanic-data').as_download(path_on_compute='titanic-data')\n",
    "print(data_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour utiliser cette référence, il faut passer par un script..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## création d'un script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'titanic-data-files/titanic.csv'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, shutil\n",
    "\n",
    "# Create a folder for the experiment files\n",
    "script_folder_name = 'script/3-titanic-files'\n",
    "experiment_folder = './' + script_folder_name\n",
    "os.makedirs(script_folder_name, exist_ok=True)\n",
    "\n",
    "# Copy the data file into the experiment folder\n",
    "shutil.copy('data/titanic/train.csv', os.path.join(script_folder_name, \"titanic.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting titanic-data-files/titanic-data.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_folder_name/titanic-data.py\n",
    "\n",
    "from azureml.core import Run\n",
    "import pandas as pd\n",
    "\n",
    "# Get the args\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--data-folder', type=str, dest='data_folder', help='data folder reference')\n",
    "args = parser.parse_args()\n",
    "\n",
    "# Get the experiment run context\n",
    "run = Run.get_context()\n",
    "\n",
    "\n",
    "# load the titanic data from the data reference\n",
    "data_folder = args.data_folder\n",
    "print(\"Loading data from\", data_folder)\n",
    "# Load all files and concatenate their contents as a single dataframe\n",
    "all_files = os.listdir(data_folder)\n",
    "titanic = pd.concat((pd.read_csv(os.path.join(data_folder,csv_file)) for csv_file in all_files))\n",
    "\n",
    "\n",
    "# Count the rows and log the result\n",
    "row_count = (len(titanic))\n",
    "run.log('observations', row_count)\n",
    "print('Analyzing {} rows of data'.format(row_count))\n",
    "\n",
    "# Save a sample of the data and upload it to the experiment output\n",
    "titanic.sample(100).to_csv('sample.csv', index=False, header=True)\n",
    "run.upload_file(name = 'outputs/sample.csv', path_or_stream = 'sample.csv')\n",
    "\n",
    "# Complete the run\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71acc8d5bac34d5ba6debf97763b97fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', '…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/titanic-data/runs/titanic-data_1600099525_73e110bb?wsid=/subscriptions/9114a63e-9210-4e32-97ca-b7d9e8ac403d/resourcegroups/jt-dp100-ressources/workspaces/jt-dp100\", \"run_id\": \"titanic-data_1600099525_73e110bb\", \"run_properties\": {\"run_id\": \"titanic-data_1600099525_73e110bb\", \"created_utc\": \"2020-09-14T16:05:25.711578Z\", \"properties\": {\"_azureml.ComputeTargetType\": \"local\", \"ContentSnapshotId\": \"c3a4973e-88fc-448e-a5f7-9cb83c614199\", \"azureml.git.repository_uri\": \"https://github.com/jtobelem-simplon/prepa-dp100.git\", \"mlflow.source.git.repoURL\": \"https://github.com/jtobelem-simplon/prepa-dp100.git\", \"azureml.git.branch\": \"master\", \"mlflow.source.git.branch\": \"master\", \"azureml.git.commit\": \"2d45093ddce878c37e597457953a961b3ad2cf28\", \"mlflow.source.git.commit\": \"2d45093ddce878c37e597457953a961b3ad2cf28\", \"azureml.git.dirty\": \"True\"}, \"tags\": {}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": \"2020-09-14T16:05:42.454757Z\", \"status\": \"Completed\", \"log_files\": {\"azureml-logs/60_control_log.txt\": \"https://jtdp1009046233469.blob.core.windows.net/azureml/ExperimentRun/dcid.titanic-data_1600099525_73e110bb/azureml-logs/60_control_log.txt?sv=2019-02-02&sr=b&sig=yyQcfwQdddd8HsnahFfabxAd81Rbqz%2FyDtTujcOqDno%3D&st=2020-09-14T15%3A55%3A47Z&se=2020-09-15T00%3A05%3A47Z&sp=r\", \"azureml-logs/70_driver_log.txt\": \"https://jtdp1009046233469.blob.core.windows.net/azureml/ExperimentRun/dcid.titanic-data_1600099525_73e110bb/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=KIyZBoS6doCLJ%2FEKzjMExinIErdvDlYVKWbryPEF8u8%3D&st=2020-09-14T15%3A55%3A47Z&se=2020-09-15T00%3A05%3A47Z&sp=r\", \"logs/azureml/10_azureml.log\": \"https://jtdp1009046233469.blob.core.windows.net/azureml/ExperimentRun/dcid.titanic-data_1600099525_73e110bb/logs/azureml/10_azureml.log?sv=2019-02-02&sr=b&sig=uyRfvYZLoNLmCSdGmIaemBNJ%2BzCAx2VP5ecFRXuIBw0%3D&st=2020-09-14T15%3A55%3A34Z&se=2020-09-15T00%3A05%3A34Z&sp=r\"}, \"log_groups\": [[\"logs/azureml/10_azureml.log\"], [\"azureml-logs/60_control_log.txt\"], [\"azureml-logs/70_driver_log.txt\"]], \"run_duration\": \"0:00:16\"}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [{\"name\": \"observations\", \"run_id\": \"titanic-data_1600099525_73e110bb\", \"categories\": [0], \"series\": [{\"data\": [891]}]}], \"run_logs\": \"[2020-09-14T16:05:28.373614] Entering context manager injector.\\n[context_manager_injector.py] Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'DataStoreCopy:context_managers.DataStores', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError'], invocation=['titanic-data.py', '--data-folder', 'titanic-data/titanic-data'])\\nStarting the daemon thread to refresh tokens in background for process with pid = 10\\nAcquired lockfile /tmp/titanic-data_1600099525_73e110bb-datastore.lock to downloading input data references\\nDownloading titanic-data/train.csv\\nDownloaded titanic-data/train.csv, 1 files out of an estimated total of 1\\nEntering Run History Context Manager.\\nCurrent directory:  /azureml-run\\nPreparing to call script [ titanic-data.py ] with arguments: ['--data-folder', 'titanic-data/titanic-data']\\nAfter variable expansion, calling script [ titanic-data.py ] with arguments: ['--data-folder', 'titanic-data/titanic-data']\\n\\nScript type = None\\nLoading data from titanic-data/titanic-data\\nAnalyzing 891 rows of data\\nStarting the daemon thread to refresh tokens in background for process with pid = 10\\n\\n\\nThe experiment completed successfully. Finalizing run...\\nLogging experiment finalizing status in history service.\\n[2020-09-14T16:05:34.253882] TimeoutHandler __init__\\n[2020-09-14T16:05:34.253917] TimeoutHandler __enter__\\nCleaning up all outstanding Run operations, waiting 300.0 seconds\\n2 items cleaning up...\\nCleanup took 0.3600022792816162 seconds\\n[2020-09-14T16:05:35.128569] TimeoutHandler __exit__\\n[2020-09-14T16:05:35.474069] TimeoutHandler __init__\\n[2020-09-14T16:05:35.474133] TimeoutHandler __enter__\\n[2020-09-14T16:05:35.474587] TimeoutHandler __exit__\\n\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.8.0\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'titanic-data_1600099525_73e110bb',\n",
       " 'target': 'local',\n",
       " 'status': 'Finalizing',\n",
       " 'startTimeUtc': '2020-09-14T16:05:27.345229Z',\n",
       " 'properties': {'_azureml.ComputeTargetType': 'local',\n",
       "  'ContentSnapshotId': 'c3a4973e-88fc-448e-a5f7-9cb83c614199',\n",
       "  'azureml.git.repository_uri': 'https://github.com/jtobelem-simplon/prepa-dp100.git',\n",
       "  'mlflow.source.git.repoURL': 'https://github.com/jtobelem-simplon/prepa-dp100.git',\n",
       "  'azureml.git.branch': 'master',\n",
       "  'mlflow.source.git.branch': 'master',\n",
       "  'azureml.git.commit': '2d45093ddce878c37e597457953a961b3ad2cf28',\n",
       "  'mlflow.source.git.commit': '2d45093ddce878c37e597457953a961b3ad2cf28',\n",
       "  'azureml.git.dirty': 'True'},\n",
       " 'inputDatasets': [],\n",
       " 'runDefinition': {'script': 'titanic-data.py',\n",
       "  'scriptType': None,\n",
       "  'useAbsolutePath': False,\n",
       "  'arguments': ['--data-folder',\n",
       "   '$AZUREML_DATAREFERENCE_d7d15bbc0066494b9596438a9a6e1301'],\n",
       "  'sourceDirectoryDataStore': None,\n",
       "  'framework': 'Python',\n",
       "  'communicator': 'None',\n",
       "  'target': 'local',\n",
       "  'dataReferences': {'d7d15bbc0066494b9596438a9a6e1301': {'dataStoreName': 'workspaceblobstore',\n",
       "    'mode': 'Download',\n",
       "    'pathOnDataStore': 'titanic-data',\n",
       "    'pathOnCompute': 'titanic-data',\n",
       "    'overwrite': False}},\n",
       "  'data': {},\n",
       "  'outputData': {},\n",
       "  'jobName': None,\n",
       "  'maxRunDurationSeconds': None,\n",
       "  'nodeCount': 1,\n",
       "  'environment': {'name': 'Experiment titanic-data Environment',\n",
       "   'version': 'Autosave_2020-09-14T16:00:32Z_c26e9f42',\n",
       "   'python': {'interpreterPath': 'python',\n",
       "    'userManagedDependencies': False,\n",
       "    'condaDependencies': {'channels': ['anaconda', 'conda-forge'],\n",
       "     'dependencies': ['python=3.6.2',\n",
       "      {'pip': ['azureml-defaults',\n",
       "        'scikit-learn==0.20.3',\n",
       "        'scipy==1.2.1',\n",
       "        'joblib==0.13.2']}],\n",
       "     'name': 'azureml_ba9520bf386d662001eeb9523395794e'},\n",
       "    'baseCondaEnvironment': None},\n",
       "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'docker': {'baseImage': 'mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20200423.v1',\n",
       "    'platform': {'os': 'Linux', 'architecture': 'amd64'},\n",
       "    'baseDockerfile': None,\n",
       "    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n",
       "    'enabled': True,\n",
       "    'arguments': []},\n",
       "   'spark': {'repositories': [], 'packages': [], 'precachePackages': False},\n",
       "   'inferencingStackVersion': None},\n",
       "  'history': {'outputCollection': True,\n",
       "   'directoriesToWatch': ['logs'],\n",
       "   'enableMLflowTracking': True,\n",
       "   'snapshotProject': True},\n",
       "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'parallelTask': {'maxRetriesPerWorker': 0,\n",
       "   'workerCountPerNode': 1,\n",
       "   'terminalExitCodes': None,\n",
       "   'configuration': {}},\n",
       "  'amlCompute': {'name': None,\n",
       "   'vmSize': None,\n",
       "   'retainCluster': False,\n",
       "   'clusterMaxNodeCount': 1},\n",
       "  'aiSuperComputer': {'instanceType': None,\n",
       "   'frameworkImage': None,\n",
       "   'imageVersion': None,\n",
       "   'location': None},\n",
       "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
       "  'mpi': {'processCountPerNode': 1},\n",
       "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
       "  'containerInstance': {'region': None, 'cpuCores': 2, 'memoryGb': 3.5},\n",
       "  'exposedPorts': None,\n",
       "  'docker': {'useDocker': True,\n",
       "   'sharedVolumes': True,\n",
       "   'shmSize': '2g',\n",
       "   'arguments': []},\n",
       "  'cmk8sCompute': {'configuration': {}},\n",
       "  'cmAksCompute': {'configuration': {}}},\n",
       " 'logFiles': {'azureml-logs/60_control_log.txt': 'https://jtdp1009046233469.blob.core.windows.net/azureml/ExperimentRun/dcid.titanic-data_1600099525_73e110bb/azureml-logs/60_control_log.txt?sv=2019-02-02&sr=b&sig=YTBV%2BdSIt%2FyDByOn8B0UdXq8dpPW687cLwQKq2pOqtA%3D&st=2020-09-14T15%3A55%3A36Z&se=2020-09-15T00%3A05%3A36Z&sp=r',\n",
       "  'azureml-logs/70_driver_log.txt': 'https://jtdp1009046233469.blob.core.windows.net/azureml/ExperimentRun/dcid.titanic-data_1600099525_73e110bb/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=rij0bql9lMXLQZNeUAqRr3QhOQWBvqclpAWmd5533ek%3D&st=2020-09-14T15%3A55%3A36Z&se=2020-09-15T00%3A05%3A36Z&sp=r',\n",
       "  'logs/azureml/10_azureml.log': 'https://jtdp1009046233469.blob.core.windows.net/azureml/ExperimentRun/dcid.titanic-data_1600099525_73e110bb/logs/azureml/10_azureml.log?sv=2019-02-02&sr=b&sig=uyRfvYZLoNLmCSdGmIaemBNJ%2BzCAx2VP5ecFRXuIBw0%3D&st=2020-09-14T15%3A55%3A34Z&se=2020-09-15T00%3A05%3A34Z&sp=r'}}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.train.sklearn import SKLearn\n",
    "from azureml.core import Experiment\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "# Set up the parameters\n",
    "script_params = {\n",
    "    '--data-folder': data_ref # data reference to download files from datastore\n",
    "}\n",
    "\n",
    "\n",
    "# Create an estimator\n",
    "estimator = SKLearn(source_directory=experiment_folder,\n",
    "                    entry_script='titanic-data.py',\n",
    "                    script_params=script_params,\n",
    "                    compute_target = 'local'\n",
    "                   )\n",
    "\n",
    "# Create an experiment\n",
    "experiment_name = 'titanic-data'\n",
    "experiment = Experiment(workspace = ws, name = experiment_name)\n",
    "\n",
    "# Run the experiment\n",
    "run = experiment.submit(config=estimator)\n",
    "# Show the run details while running\n",
    "RunDetails(run).show()\n",
    "run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Avec les datasets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from azureml.core import Dataset\n",
    "\n",
    "default_ds = ws.get_default_datastore()\n",
    "\n",
    "if 'titanic dataset' not in ws.datasets:\n",
    "    default_ds.upload_files(files=['./data/titanic/train.csv'], # Upload the titanic csv files in /data\n",
    "                        target_path='titanic-data/', # Put it in a folder path in the datastore\n",
    "                        overwrite=True, # Replace existing files of the same name\n",
    "                        show_progress=True)\n",
    "\n",
    "    #Create a tabular dataset from the path on the datastore (this may take a short while)\n",
    "    tab_data_set = Dataset.Tabular.from_delimited_files(path=(default_ds, 'titanic-data/*.csv'))\n",
    "\n",
    "    # Register the tabular dataset\n",
    "    try:\n",
    "        tab_data_set = tab_data_set.register(workspace=ws, \n",
    "                                name='titanic dataset',\n",
    "                                description='titanic data',\n",
    "                                tags = {'format':'CSV'},\n",
    "                                create_new_version=True)\n",
    "        print('Dataset registered.')\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "else:\n",
    "    print('Dataset already registered.')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "titanic_ds = ws.datasets.get(\"titanic dataset\")\n",
    "titanic_ds.to_pandas_dataframe().head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ne pas oublier à la fin de l'expérience!!\n",
    "(si votre travail à utilisé une instance de calcul)\n",
    "\n",
    "<img src='https://github.com/jtobelem-simplon/prepa-dp100/blob/master/images/down.png?raw=true'>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already registered.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Dataset\n",
    "\n",
    "default_ds = ws.get_default_datastore()\n",
    "\n",
    "if 'titanic dataset' not in ws.datasets:\n",
    "    default_ds.upload_files(files=['./data/titanic/train.csv'], # Upload the titanic csv files in /data\n",
    "                        target_path='titanic-data/', # Put it in a folder path in the datastore\n",
    "                        overwrite=True, # Replace existing files of the same name\n",
    "                        show_progress=True)\n",
    "\n",
    "    #Create a tabular dataset from the path on the datastore (this may take a short while)\n",
    "    tab_data_set = Dataset.Tabular.from_delimited_files(path=(default_ds, 'titanic-data/*.csv'))\n",
    "\n",
    "    # Register the tabular dataset\n",
    "    try:\n",
    "        tab_data_set = tab_data_set.register(workspace=ws, \n",
    "                                name='titanic dataset',\n",
    "                                description='titanic data',\n",
    "                                tags = {'format':'CSV'},\n",
    "                                create_new_version=True)\n",
    "        print('Dataset registered.')\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "else:\n",
    "    print('Dataset already registered.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500  None        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250  None        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500  None        S  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_ds = ws.datasets.get(\"titanic dataset\")\n",
    "titanic_ds.to_pandas_dataframe().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ne pas oublier à la fin de l'expérience!!\n",
    "(si votre travail à utilisé une instance de calcul)\n",
    "\n",
    "<img src='https://github.com/jtobelem-simplon/prepa-dp100/blob/master/images/down.png?raw=true'>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop toutes les instances de calcul\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute, ComputeInstance\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "for compute in ComputeTarget.list(ws):\n",
    "    if type(compute) is ComputeInstance and compute.get_status().state != 'Stopped':\n",
    "        print('try to stop compute', compute.name)\n",
    "        compute.stop(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vm-ds3-v2 {\n",
      "  \"errors\": [],\n",
      "  \"creationTime\": \"2020-05-27T10:12:38.674242+00:00\",\n",
      "  \"createdBy\": {\n",
      "    \"userId\": \"c88a830e-65d5-4e6d-a890-6d4497d2e6bd\",\n",
      "    \"userOrgId\": \"0840dabf-0881-4071-9392-f25b2728592f\"\n",
      "  },\n",
      "  \"modifiedTime\": \"2020-09-10T13:17:50.819127+00:00\",\n",
      "  \"state\": \"Stopped\",\n",
      "  \"vmSize\": \"STANDARD_DS3_V2\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# liste tous les compute pour vérifier qu'elles sont éteintes\n",
    "for compute in ComputeTarget.list(ws):\n",
    "    if type(compute) is ComputeInstance:\n",
    "        print(compute.name, compute.get_status())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ressources\n",
    "\n",
    "[api azure](https://docs.microsoft.com/en-us/python/api/azureml-core)\n",
    "\n",
    "[parcours d'apprentissage microsoft](https://docs.microsoft.com/fr-fr/learn/paths/build-ai-solutions-with-azure-ml-service/)\n",
    "\n",
    "[le repository microsoft](https://github.com/MicrosoftDocs/mslearn-aml-labs.git)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}