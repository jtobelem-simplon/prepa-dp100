{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://github.com/jtobelem-simplon/prepa-dp100/blob/master/images/top.png?raw=true'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration (à lancer avant tous les notebooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.8.5'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version de python\n",
    "import platform\n",
    "platform.python_version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# packages in environment at /home/lab/anaconda3/envs/azure:\r\n",
      "#\r\n",
      "# Name                    Version                   Build  Channel\r\n",
      "_libgcc_mutex             0.1                        main  \r\n",
      "adal                      1.2.4                    pypi_0    pypi\r\n",
      "applicationinsights       0.11.9                   pypi_0    pypi\r\n",
      "async_generator           1.10                       py_0    conda-forge\r\n",
      "attrs                     20.2.0             pyh9f0ad1d_0    conda-forge\r\n",
      "azure-common              1.1.25                   pypi_0    pypi\r\n",
      "azure-core                1.8.1                    pypi_0    pypi\r\n",
      "azure-graphrbac           0.61.1                   pypi_0    pypi\r\n",
      "azure-identity            1.2.0                    pypi_0    pypi\r\n",
      "azure-mgmt-authorization  0.61.0                   pypi_0    pypi\r\n",
      "azure-mgmt-containerregistry 2.8.0                    pypi_0    pypi\r\n",
      "azure-mgmt-keyvault       2.2.0                    pypi_0    pypi\r\n",
      "azure-mgmt-resource       10.2.0                   pypi_0    pypi\r\n",
      "azure-mgmt-storage        11.2.0                   pypi_0    pypi\r\n",
      "azureml-automl-core       1.13.0                   pypi_0    pypi\r\n",
      "azureml-core              1.13.0                   pypi_0    pypi\r\n",
      "azureml-dataprep          2.0.8                    pypi_0    pypi\r\n",
      "azureml-dataprep-native   20.0.2                   pypi_0    pypi\r\n",
      "azureml-dataset-runtime   1.13.0                   pypi_0    pypi\r\n",
      "azureml-pipeline          1.13.0                   pypi_0    pypi\r\n",
      "azureml-pipeline-core     1.13.0                   pypi_0    pypi\r\n",
      "azureml-pipeline-steps    1.13.0                   pypi_0    pypi\r\n",
      "azureml-sdk               1.13.0                   pypi_0    pypi\r\n",
      "azureml-telemetry         1.13.0                   pypi_0    pypi\r\n",
      "azureml-train             1.13.0                   pypi_0    pypi\r\n",
      "azureml-train-automl-client 1.13.0.post1             pypi_0    pypi\r\n",
      "azureml-train-core        1.13.0                   pypi_0    pypi\r\n",
      "azureml-train-restclients-hyperdrive 1.13.0                   pypi_0    pypi\r\n",
      "backcall                  0.2.0              pyh9f0ad1d_0    conda-forge\r\n",
      "backports                 1.0                        py_2    conda-forge\r\n",
      "backports-tempfile        1.0                      pypi_0    pypi\r\n",
      "backports-weakref         1.0.post1                pypi_0    pypi\r\n",
      "backports.functools_lru_cache 1.6.1                      py_0    conda-forge\r\n",
      "bleach                    3.1.5              pyh9f0ad1d_0    conda-forge\r\n",
      "ca-certificates           2020.6.20            hecda079_0    conda-forge\r\n",
      "certifi                   2020.6.20        py38h32f6830_0    conda-forge\r\n",
      "cffi                      1.14.3                   pypi_0    pypi\r\n",
      "chardet                   3.0.4                    pypi_0    pypi\r\n",
      "cloudpickle               1.6.0                    pypi_0    pypi\r\n",
      "contextlib2               0.6.0.post1              pypi_0    pypi\r\n",
      "cryptography              3.1                      pypi_0    pypi\r\n",
      "cycler                    0.10.0                     py_2    conda-forge\r\n",
      "dbus                      1.13.16              hb2f20db_0  \r\n",
      "decorator                 4.4.2                      py_0    conda-forge\r\n",
      "defusedxml                0.6.0                      py_0    conda-forge\r\n",
      "distro                    1.5.0                    pypi_0    pypi\r\n",
      "docker                    4.3.1                    pypi_0    pypi\r\n",
      "dotnetcore2               2.1.14                   pypi_0    pypi\r\n",
      "entrypoints               0.3             py38h32f6830_1001    conda-forge\r\n",
      "expat                     2.2.9                he1b5a44_2    conda-forge\r\n",
      "fontconfig                2.13.1            he4413a7_1000    conda-forge\r\n",
      "freetype                  2.10.2               he06d7ca_0    conda-forge\r\n",
      "fusepy                    3.0.1                    pypi_0    pypi\r\n",
      "glib                      2.65.0               h3eb4bd4_0  \r\n",
      "gst-plugins-base          1.14.0               hbbd80ab_1  \r\n",
      "gstreamer                 1.14.0               hb31296c_0  \r\n",
      "icu                       58.2              hf484d3e_1000    conda-forge\r\n",
      "idna                      2.10                     pypi_0    pypi\r\n",
      "importlib-metadata        1.7.0            py38h32f6830_0    conda-forge\r\n",
      "importlib_metadata        1.7.0                         0    conda-forge\r\n",
      "ipykernel                 5.3.4            py38h23f93f0_0    conda-forge\r\n",
      "ipython                   7.18.1           py38h1cdfbd6_0    conda-forge\r\n",
      "ipython_genutils          0.2.0                      py_1    conda-forge\r\n",
      "ipywidgets                7.5.1              pyh9f0ad1d_1    conda-forge\r\n",
      "isodate                   0.6.0                    pypi_0    pypi\r\n",
      "jedi                      0.17.2           py38h32f6830_0    conda-forge\r\n",
      "jeepney                   0.4.3                    pypi_0    pypi\r\n",
      "jinja2                    2.11.2             pyh9f0ad1d_0    conda-forge\r\n",
      "jmespath                  0.10.0                   pypi_0    pypi\r\n",
      "joblib                    0.16.0                     py_0    conda-forge\r\n",
      "jpeg                      9d                   h516909a_0    conda-forge\r\n",
      "jsonpickle                1.4.1                    pypi_0    pypi\r\n",
      "jsonschema                3.2.0            py38h32f6830_1    conda-forge\r\n",
      "jupyter                   1.0.0                      py_2    conda-forge\r\n",
      "jupyter_client            6.1.7                      py_0    conda-forge\r\n",
      "jupyter_console           6.2.0                      py_0    conda-forge\r\n",
      "jupyter_contrib_core      0.3.3                      py_2    conda-forge\r\n",
      "jupyter_contrib_nbextensions 0.5.1                    py38_0    conda-forge\r\n",
      "jupyter_core              4.6.3            py38h32f6830_1    conda-forge\r\n",
      "jupyter_highlight_selected_word 0.2.0                 py38_1000    conda-forge\r\n",
      "jupyter_latex_envs        1.4.6                 py38_1000    conda-forge\r\n",
      "jupyter_nbextensions_configurator 0.4.1            py38h32f6830_1    conda-forge\r\n",
      "jupyterlab_pygments       0.1.1              pyh9f0ad1d_0    conda-forge\r\n",
      "kiwisolver                1.2.0            py38hbf85e49_0    conda-forge\r\n",
      "lcms2                     2.11                 hbd6801e_0    conda-forge\r\n",
      "ld_impl_linux-64          2.33.1               h53a641e_7  \r\n",
      "libblas                   3.8.0               17_openblas    conda-forge\r\n",
      "libcblas                  3.8.0               17_openblas    conda-forge\r\n",
      "libedit                   3.1.20191231         h14c3975_1  \r\n",
      "libffi                    3.3                  he6710b0_2  \r\n",
      "libgcc-ng                 9.1.0                hdf63c60_0  \r\n",
      "libgfortran-ng            7.5.0               hdf63c60_16    conda-forge\r\n",
      "liblapack                 3.8.0               17_openblas    conda-forge\r\n",
      "libopenblas               0.3.10          pthreads_hb3c22a3_4    conda-forge\r\n",
      "libpng                    1.6.37               hed695b0_2    conda-forge\r\n",
      "libsodium                 1.0.18               h516909a_0    conda-forge\r\n",
      "libstdcxx-ng              9.1.0                hdf63c60_0  \r\n",
      "libtiff                   4.1.0                hc7e4089_6    conda-forge\r\n",
      "libuuid                   2.32.1            h14c3975_1000    conda-forge\r\n",
      "libwebp-base              1.1.0                h516909a_3    conda-forge\r\n",
      "libxcb                    1.13              h14c3975_1002    conda-forge\r\n",
      "libxml2                   2.9.10               he19cac6_1  \r\n",
      "libxslt                   1.1.34               hc22bd24_0  \r\n",
      "lxml                      4.5.2            py38hbb43d70_0    conda-forge\r\n",
      "lz4-c                     1.9.2                he1b5a44_3    conda-forge\r\n",
      "markupsafe                1.1.1            py38h1e0a361_1    conda-forge\r\n",
      "matplotlib                3.3.2                         0    conda-forge\r\n",
      "matplotlib-base           3.3.2            py38h91b0d89_0    conda-forge\r\n",
      "mistune                   0.8.4           py38h1e0a361_1001    conda-forge\r\n",
      "msal                      1.5.0                    pypi_0    pypi\r\n",
      "msal-extensions           0.1.3                    pypi_0    pypi\r\n",
      "msrest                    0.6.19                   pypi_0    pypi\r\n",
      "msrestazure               0.6.4                    pypi_0    pypi\r\n",
      "nbclient                  0.5.0                      py_0    conda-forge\r\n",
      "nbconvert                 6.0.2            py38h32f6830_0    conda-forge\r\n",
      "nbformat                  5.0.7                      py_0    conda-forge\r\n",
      "ncurses                   6.2                  he6710b0_1  \r\n",
      "ndg-httpsclient           0.5.1                    pypi_0    pypi\r\n",
      "nest-asyncio              1.4.0                      py_0    conda-forge\r\n",
      "notebook                  6.0.3            py38h32f6830_1    conda-forge\r\n",
      "numpy                     1.19.1           py38hbc27379_2    conda-forge\r\n",
      "oauthlib                  3.1.0                    pypi_0    pypi\r\n",
      "olefile                   0.46                       py_0    conda-forge\r\n",
      "openssl                   1.1.1g               h516909a_1    conda-forge\r\n",
      "packaging                 20.4               pyh9f0ad1d_0    conda-forge\r\n",
      "pandas                    1.1.2            py38h950e882_0    conda-forge\r\n",
      "pandoc                    2.10.1               h516909a_0    conda-forge\r\n",
      "pandocfilters             1.4.2                      py_1    conda-forge\r\n",
      "parso                     0.7.1              pyh9f0ad1d_0    conda-forge\r\n",
      "pathspec                  0.8.0                    pypi_0    pypi\r\n",
      "pcre                      8.44                 he1b5a44_0    conda-forge\r\n",
      "pexpect                   4.8.0            py38h32f6830_1    conda-forge\r\n",
      "pickleshare               0.7.5           py38h32f6830_1001    conda-forge\r\n",
      "pillow                    7.2.0            py38h9776b28_1    conda-forge\r\n",
      "pip                       20.2.3                     py_0    conda-forge\r\n",
      "portalocker               1.7.1                    pypi_0    pypi\r\n",
      "prometheus_client         0.8.0              pyh9f0ad1d_0    conda-forge\r\n",
      "prompt-toolkit            3.0.7                      py_0    conda-forge\r\n",
      "prompt_toolkit            3.0.7                         0    conda-forge\r\n",
      "pthread-stubs             0.4               h14c3975_1001    conda-forge\r\n",
      "ptyprocess                0.6.0                   py_1001    conda-forge\r\n",
      "pyarrow                   1.0.1                    pypi_0    pypi\r\n",
      "pyasn1                    0.4.8                    pypi_0    pypi\r\n",
      "pycparser                 2.20                     pypi_0    pypi\r\n",
      "pygments                  2.7.0                      py_0    conda-forge\r\n",
      "pyjwt                     1.7.1                    pypi_0    pypi\r\n",
      "pyopenssl                 19.1.0                   pypi_0    pypi\r\n",
      "pyparsing                 2.4.7              pyh9f0ad1d_0    conda-forge\r\n",
      "pyqt                      5.9.2            py38h05f1152_4  \r\n",
      "pyrsistent                0.17.3           py38h1e0a361_0    conda-forge\r\n",
      "python                    3.8.5                h7579374_1  \r\n",
      "python-dateutil           2.8.1                      py_0    conda-forge\r\n",
      "python_abi                3.8                      1_cp38    conda-forge\r\n",
      "pytz                      2020.1             pyh9f0ad1d_0    conda-forge\r\n",
      "pyyaml                    5.3.1            py38h1e0a361_0    conda-forge\r\n",
      "pyzmq                     19.0.2           py38ha71036d_0    conda-forge\r\n",
      "qt                        5.9.7                h5867ecd_1  \r\n",
      "qtconsole                 4.7.7              pyh9f0ad1d_0    conda-forge\r\n",
      "qtpy                      1.9.0                      py_0    conda-forge\r\n",
      "readline                  8.0                  h7b6447c_0  \r\n",
      "requests                  2.24.0                   pypi_0    pypi\r\n",
      "requests-oauthlib         1.3.0                    pypi_0    pypi\r\n",
      "ruamel-yaml               0.16.12                  pypi_0    pypi\r\n",
      "ruamel-yaml-clib          0.2.2                    pypi_0    pypi\r\n",
      "scikit-learn              0.23.2           py38hee58b96_0    conda-forge\r\n",
      "scipy                     1.5.2            py38h8c5af15_0    conda-forge\r\n",
      "secretstorage             3.1.2                    pypi_0    pypi\r\n",
      "send2trash                1.5.0                      py_0    conda-forge\r\n",
      "setuptools                49.6.0                   py38_0  \r\n",
      "sip                       4.19.13          py38he6710b0_0  \r\n",
      "six                       1.15.0             pyh9f0ad1d_0    conda-forge\r\n",
      "sqlite                    3.33.0               h62c20be_0  \r\n",
      "terminado                 0.8.3            py38h32f6830_1    conda-forge\r\n",
      "testpath                  0.4.4                      py_0    conda-forge\r\n",
      "threadpoolctl             2.1.0              pyh5ca1d4c_0    conda-forge\r\n",
      "tk                        8.6.10               hbc83047_0  \r\n",
      "tornado                   6.0.4            py38h1e0a361_1    conda-forge\r\n",
      "traitlets                 5.0.4                      py_0    conda-forge\r\n",
      "urllib3                   1.25.10                  pypi_0    pypi\r\n",
      "wcwidth                   0.2.5              pyh9f0ad1d_1    conda-forge\r\n",
      "webencodings              0.5.1                      py_1    conda-forge\r\n",
      "websocket-client          0.57.0                   pypi_0    pypi\r\n",
      "wheel                     0.35.1                     py_0  \r\n",
      "widgetsnbextension        3.5.1            py38h32f6830_1    conda-forge\r\n",
      "xorg-libxau               1.0.9                h14c3975_0    conda-forge\r\n",
      "xorg-libxdmcp             1.1.3                h516909a_0    conda-forge\r\n",
      "xz                        5.2.5                h7b6447c_0  \r\n",
      "yaml                      0.2.5                h516909a_0    conda-forge\r\n",
      "zeromq                    4.3.2                he1b5a44_3    conda-forge\r\n",
      "zipp                      3.1.0                      py_0    conda-forge\r\n",
      "zlib                      1.2.11               h7b6447c_3  \r\n",
      "zstd                      1.4.5                h6597ccf_2    conda-forge\r\n"
     ]
    }
   ],
   "source": [
    "# la liste des packages installés\n",
    "!conda list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to use Azure ML 1.13.0\n"
     ]
    }
   ],
   "source": [
    "# version de la SDK azureml\n",
    "import azureml.core\n",
    "print(\"Ready to use Azure ML\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si le notebook est executé en dehors d'Azure, il faut télécharger le fichier config.json depuis le portail https://portal.azure.com/, et le mettre dans le workspace qui contient le notebook.\n",
    "\n",
    "Si le notebook est exécuté directement depuis le workspace Azure, le fichier de config devrait déjà être là."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jt-dp100 loaded\n"
     ]
    }
   ],
   "source": [
    "# connexion au workspace\n",
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print(ws.name, \"loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enregistrement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading an estimated of 1 files\n",
      "Uploading ./data/titanic/train.csv\n",
      "Uploaded ./data/titanic/train.csv, 1 files out of an estimated total of 1\n",
      "Uploaded 1 files\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Engine process terminated. This is most likely due to system running out of memory. Please retry with increased memory. |session_id=06657b47-111c-43e4-b9ec-689d8d88c2d0",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mMemoryError\u001B[0m                               Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-5-2d59e9bb19c9>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     11\u001B[0m     \u001B[0;31m#Create a tabular dataset from the path on the datastore (this may take a short while)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 12\u001B[0;31m     \u001B[0mtab_data_set\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mDataset\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTabular\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfrom_delimited_files\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdefault_ds\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'titanic-data/*.csv'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     13\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     14\u001B[0m     \u001B[0;31m# Register the tabular dataset\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/azure/lib/python3.8/site-packages/azureml/data/_loggerfactory.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    124\u001B[0m             \u001B[0;32mwith\u001B[0m \u001B[0m_LoggerFactory\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrack_activity\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlogger\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__name__\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mactivity_type\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcustom_dimensions\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mal\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    125\u001B[0m                 \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 126\u001B[0;31m                     \u001B[0;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    127\u001B[0m                 \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    128\u001B[0m                     \u001B[0;32mif\u001B[0m \u001B[0mhasattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mal\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'activity_info'\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mhasattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'error_code'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/azure/lib/python3.8/site-packages/azureml/data/dataset_factory.py\u001B[0m in \u001B[0;36mfrom_delimited_files\u001B[0;34m(path, validate, include_path, infer_column_types, set_column_types, separator, header, partition_format, support_multi_line, empty_as_string)\u001B[0m\n\u001B[1;32m    303\u001B[0m                                            empty_as_string=empty_as_string)\n\u001B[1;32m    304\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 305\u001B[0;31m             dataflow = dataprep().read_csv(_validate_and_normalize_path(path),\n\u001B[0m\u001B[1;32m    306\u001B[0m                                            \u001B[0mverify_exists\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    307\u001B[0m                                            \u001B[0minclude_path\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/azure/lib/python3.8/site-packages/azureml/dataprep/api/readers.py\u001B[0m in \u001B[0;36mread_csv\u001B[0;34m(path, separator, header, encoding, quoting, inference_arguments, skip_rows, skip_mode, comment, include_path, archive_options, infer_column_types, verify_exists, partition_size, empty_as_string)\u001B[0m\n\u001B[1;32m     98\u001B[0m     \"\"\"\n\u001B[1;32m     99\u001B[0m     \u001B[0mskip_mode\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_default_skip_mode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mskip_mode\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mskip_rows\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 100\u001B[0;31m     \u001B[0mdf\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mDataflow\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_path_to_get_files_block\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0marchive_options\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    101\u001B[0m     \u001B[0mdf\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mparse_delimited\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mseparator\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mheader\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mencoding\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mquoting\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mskip_rows\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mskip_mode\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcomment\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpartition_size\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mempty_as_string\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    102\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/azure/lib/python3.8/site-packages/azureml/dataprep/api/dataflow.py\u001B[0m in \u001B[0;36m_path_to_get_files_block\u001B[0;34m(path, archive_options)\u001B[0m\n\u001B[1;32m   2338\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2339\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0m_is_datapath\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0m_is_datapaths\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2340\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mdatastore_to_dataflow\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2341\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mImportError\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2342\u001B[0m             \u001B[0;32mpass\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/azure/lib/python3.8/site-packages/azureml/dataprep/api/_datastore_helper.py\u001B[0m in \u001B[0;36mdatastore_to_dataflow\u001B[0;34m(data_source, query_timeout)\u001B[0m\n\u001B[1;32m     25\u001B[0m         \u001B[0mdatastore_values\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     26\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0msource\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mdata_source\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 27\u001B[0;31m             \u001B[0mdatastore\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdatastore_value\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mget_datastore_value\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msource\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     28\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0m_is_fs_datastore\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdatastore\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     29\u001B[0m                 \u001B[0;32mraise\u001B[0m \u001B[0mNotSupportedDatastoreTypeError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdatastore\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/azure/lib/python3.8/site-packages/azureml/dataprep/api/_datastore_helper.py\u001B[0m in \u001B[0;36mget_datastore_value\u001B[0;34m(data_source)\u001B[0m\n\u001B[1;32m     78\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     79\u001B[0m     \u001B[0mworkspace\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdatastore\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mworkspace\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 80\u001B[0;31m     \u001B[0m_set_auth_type\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mworkspace\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     81\u001B[0m     return (datastore, DatastoreValue(\n\u001B[1;32m     82\u001B[0m         \u001B[0msubscription\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mworkspace\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msubscription_id\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/azure/lib/python3.8/site-packages/azureml/dataprep/api/_datastore_helper.py\u001B[0m in \u001B[0;36m_set_auth_type\u001B[0;34m(workspace)\u001B[0m\n\u001B[1;32m    138\u001B[0m         \u001B[0mget_engine_api\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mset_aml_auth\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mSetAmlAuthMessageArgument\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mAuthType\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mSERVICEPRINCIPAL\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mjson\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdumps\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mauth\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    139\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 140\u001B[0;31m         \u001B[0mget_engine_api\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mset_aml_auth\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mSetAmlAuthMessageArgument\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mAuthType\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mDERIVED\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mjson\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdumps\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mauth\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    141\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    142\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/azure/lib/python3.8/site-packages/azureml/dataprep/api/engineapi/api.py\u001B[0m in \u001B[0;36mget_engine_api\u001B[0;34m()\u001B[0m\n\u001B[1;32m     16\u001B[0m     \u001B[0;32mglobal\u001B[0m \u001B[0m_engine_api\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     17\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0m_engine_api\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 18\u001B[0;31m         \u001B[0m_engine_api\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mEngineAPI\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     19\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     20\u001B[0m         \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_dataset_resolver\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mregister_dataset_resolver\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/azure/lib/python3.8/site-packages/azureml/dataprep/api/engineapi/api.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     57\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     58\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_message_channel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlaunch_engine\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 59\u001B[0;31m         \u001B[0mconnect_to_requests_channel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     60\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     61\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_message_channel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mon_relaunch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mconnect_to_requests_channel\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/azure/lib/python3.8/site-packages/azureml/dataprep/api/engineapi/api.py\u001B[0m in \u001B[0;36mconnect_to_requests_channel\u001B[0;34m()\u001B[0m\n\u001B[1;32m     53\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     54\u001B[0m         \u001B[0;32mdef\u001B[0m \u001B[0mconnect_to_requests_channel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 55\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_engine_server_secret\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msync_host_secret\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrequests_channel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mhost_secret\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     56\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_engine_server_port\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msync_host_channel_port\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrequests_channel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mport\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     57\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/azure/lib/python3.8/site-packages/azureml/dataprep/api/_aml_helper.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(op_code, message, cancellation_token)\u001B[0m\n\u001B[1;32m     36\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mchanged\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     37\u001B[0m                 \u001B[0mengine_api_func\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mupdate_environment_variable\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mchanged\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 38\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0msend_message_func\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mop_code\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmessage\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcancellation_token\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     39\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     40\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mwrapper\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/azure/lib/python3.8/site-packages/azureml/dataprep/api/engineapi/api.py\u001B[0m in \u001B[0;36msync_host_secret\u001B[0;34m(self, message_args, cancellation_token)\u001B[0m\n\u001B[1;32m    253\u001B[0m     \u001B[0;34m@\u001B[0m\u001B[0mupdate_aml_env_vars\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mget_engine_api\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    254\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0msync_host_secret\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmessage_args\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcancellation_token\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mCancellationToken\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 255\u001B[0;31m         \u001B[0mresponse\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_message_channel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msend_message\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'Engine.SyncHostSecret'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmessage_args\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcancellation_token\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    256\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mresponse\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    257\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/azure/lib/python3.8/site-packages/azureml/dataprep/api/engineapi/engine.py\u001B[0m in \u001B[0;36msend_message\u001B[0;34m(self, op_code, message, cancellation_token)\u001B[0m\n\u001B[1;32m    178\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    179\u001B[0m             \u001B[0;32mwhile\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 180\u001B[0;31m                 \u001B[0mresponse\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_read_response\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    181\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0;34m'error'\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mresponse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    182\u001B[0m                     \u001B[0mraise_engine_error\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mresponse\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'error'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/azure/lib/python3.8/site-packages/azureml/dataprep/api/engineapi/engine.py\u001B[0m in \u001B[0;36m_read_response\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    140\u001B[0m                 'Engine process terminated. Please try running again.'))\n\u001B[1;32m    141\u001B[0m             \u001B[0mlog\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0merror\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrepr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0merror\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 142\u001B[0;31m             \u001B[0;32mraise\u001B[0m \u001B[0merror\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    143\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    144\u001B[0m         \u001B[0mparsed\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mMemoryError\u001B[0m: Engine process terminated. This is most likely due to system running out of memory. Please retry with increased memory. |session_id=06657b47-111c-43e4-b9ec-689d8d88c2d0"
     ]
    }
   ],
   "source": [
    "from azureml.core import Dataset\n",
    "\n",
    "default_ds = ws.get_default_datastore()\n",
    "\n",
    "if 'titanic dataset' not in ws.datasets:\n",
    "    default_ds.upload_files(files=['./data/titanic/train.csv'], # Upload the diabetes csv files in /data\n",
    "                        target_path='titanic-data/', # Put it in a folder path in the datastore\n",
    "                        overwrite=True, # Replace existing files of the same name\n",
    "                        show_progress=True)\n",
    "\n",
    "    #Create a tabular dataset from the path on the datastore (this may take a short while)\n",
    "    tab_data_set = Dataset.Tabular.from_delimited_files(path=(default_ds, 'titanic-data/*.csv'))\n",
    "\n",
    "    # Register the tabular dataset\n",
    "    try:\n",
    "        tab_data_set = tab_data_set.register(workspace=ws, \n",
    "                                name='titanic dataset',\n",
    "                                description='titanic data',\n",
    "                                tags = {'format':'CSV'},\n",
    "                                create_new_version=True)\n",
    "        print('Dataset registered.')\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "else:\n",
    "    print('Dataset already registered.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création d'un environnement (conda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "# Create a Python environment for the experiment\n",
    "titanic_env = Environment(\"titanic-experiment-env\")\n",
    "titanic_env.python.user_managed_dependencies = False # Let Azure ML manage dependencies\n",
    "titanic_env.docker.enabled = True # Use a docker container\n",
    "\n",
    "# Create a set of package dependencies (conda or pip as required)\n",
    "titanic_packages = CondaDependencies.create(conda_packages=['scikit-learn'],\n",
    "                                          pip_packages=['azureml-defaults', 'azureml-dataprep[pandas]'])\n",
    "\n",
    "# Add the dependencies to the environment\n",
    "titanic_env.python.conda_dependencies = titanic_packages\n",
    "\n",
    "print(titanic_env.name, 'defined.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the environment\n",
    "titanic_env.register(workspace=ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création du script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create a folder for the experiment files\n",
    "experiment_folder = 'titanic_training_logistic'\n",
    "os.makedirs(experiment_folder, exist_ok=True)\n",
    "print(experiment_folder, 'folder created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $experiment_folder/titanic_training.py\n",
    "from azureml.core import Run\n",
    "import joblib\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Get the experiment run context\n",
    "run = Run.get_context()\n",
    "\n",
    "# load the diabetes data (passed as an input dataset)\n",
    "print(\"Loading Data...\")\n",
    "titanic = run.input_datasets['titanic'].to_pandas_dataframe()\n",
    "\n",
    "\n",
    "features = [\"Age\",\"Pclass\",\"SibSp\", \"Parch\", \"Fare\",\"Sex\", \"Embarked\"]\n",
    "\n",
    "X = pd.get_dummies(train_data[features])\n",
    "y = train_data[\"Survived\"]\n",
    "\n",
    "# missing values\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "imputed_X = pd.DataFrame(imputer.fit_transform(X))\n",
    "imputed_X.columns = X.columns\n",
    "imputed_X[[\"Age\",\"Pclass\",\"SibSp\", \"Parch\", \"Fare\"]] = imputed_X[[\"Age\",\"Pclass\",\"SibSp\", \"Parch\", \"Fare\"]].astype('int')\n",
    "\n",
    "\n",
    "# Break off validation set from training data\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(imputed_X, y, train_size=0.8, test_size=0.2,\n",
    "                                                                random_state=0)\n",
    "\n",
    "# model\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# score\n",
    "predictions = model.predict(X_valid)\n",
    "\n",
    "mae = mean_absolute_error(predictions.astype('int'), y_valid)\n",
    "acc = accuracy_score(y_valid, predictions.astype('int'))\n",
    "print(\"mae : {}, accuracy : {}\".format(mae, acc))\n",
    "run.log('mae', mae)\n",
    "run.log('acc',acc)\n",
    "\n",
    "# Save the trained model in the outputs folder\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "joblib.dump(value=model, filename='outputs/titanic_model.pkl')\n",
    "\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execution du script en local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.estimator import Estimator\n",
    "from azureml.core import Experiment\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "\n",
    "# Get the training dataset\n",
    "titanic_ds = ws.datasets.get(\"titanic dataset\")\n",
    "\n",
    "# Create an estimator\n",
    "estimator = Estimator(source_directory=experiment_folder,\n",
    "                      inputs=[titanic_ds.as_named_input('titanic')],\n",
    "                      compute_target = 'local',\n",
    "                      environment_definition = titanic_env,\n",
    "                      entry_script='titanic_training.py')\n",
    "\n",
    "# Create an experiment\n",
    "experiment = Experiment(workspace = ws, name = 'titanic-training')\n",
    "\n",
    "# Run the experiment\n",
    "run = experiment.submit(config=estimator)\n",
    "# Show the run details while running\n",
    "RunDetails(run).show()\n",
    "run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execution du script sur un cluster distant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provisionnement ou récupération d'un cluster existant appelé \"aml-cluster\". Voir [tutoriel microsoft : partie 1](https://docs.microsoft.com/en-us/azure/machine-learning/tutorial-train-models-with-aml#train-on-a-remote-cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import AmlCompute\n",
    "from azureml.core.compute import ComputeTarget\n",
    "import os\n",
    "\n",
    "# choose a name for your cluster\n",
    "compute_name = os.environ.get(\"AML_COMPUTE_CLUSTER_NAME\", \"aml-cluster\")\n",
    "compute_min_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MIN_NODES\", 0)\n",
    "compute_max_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MAX_NODES\", 4)\n",
    "\n",
    "# This example uses CPU VM. For using GPU VM, set SKU to STANDARD_NC6\n",
    "vm_size = os.environ.get(\"AML_COMPUTE_CLUSTER_SKU\", \"STANDARD_D2_V2\")\n",
    "\n",
    "\n",
    "if compute_name in ws.compute_targets:\n",
    "    compute_target = ws.compute_targets[compute_name]\n",
    "    if compute_target and type(compute_target) is AmlCompute:\n",
    "        print('found compute target. just use it. ' + compute_name)\n",
    "else:\n",
    "    print('creating a new compute target...')\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size=vm_size,\n",
    "                                                                min_nodes=compute_min_nodes,\n",
    "                                                                max_nodes=compute_max_nodes)\n",
    "\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(\n",
    "        ws, compute_name, provisioning_config)\n",
    "\n",
    "    # can poll for a minimum number of nodes and for a specific timeout.\n",
    "    # if no min node count is provided it will use the scale settings for the cluster\n",
    "    compute_target.wait_for_completion(\n",
    "        show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "\n",
    "    # For a more detailed view of current AmlCompute status, use get_status()\n",
    "    print(compute_target.get_status().serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Même estimator que dans la partie précédente mais avec le cluster dans la compute_target. Il va falloir provisionner le cluster (normalement 0 noeuds actifs initialement), cela peut prendre un peu de temps..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.estimator import Estimator\n",
    "from azureml.core import Experiment\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "\n",
    "# Get the training dataset\n",
    "titanic_ds = ws.datasets.get(\"titanic dataset\")\n",
    "\n",
    "# Create an estimator\n",
    "estimator = Estimator(source_directory=experiment_folder,\n",
    "                      inputs=[titanic_ds.as_named_input('titanic')],\n",
    "                      compute_target = compute_target,\n",
    "                      environment_definition = titanic_env,\n",
    "                      entry_script='titanic_training.py')\n",
    "\n",
    "# Create an experiment\n",
    "experiment = Experiment(workspace = ws, name = 'titanic-training')\n",
    "\n",
    "# Run the experiment\n",
    "run = experiment.submit(config=estimator)\n",
    "# Show the run details while running\n",
    "RunDetails(run).show()\n",
    "run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ne pas oublier à la fin de l'expérience!!\n",
    "(si votre travail à utilisé une instance de calcul)\n",
    "\n",
    "<img src='https://github.com/jtobelem-simplon/prepa-dp100/blob/master/images/down.png?raw=true'>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop toutes les instances de calcul\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute, ComputeInstance\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "for compute in ComputeTarget.list(ws):\n",
    "    if type(compute) is ComputeInstance and compute.get_status().state == 'Running':\n",
    "        print('try to stop compute', compute.name)\n",
    "        compute.stop(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# liste tous les compute pour vérifier qu'elles sont éteintes\n",
    "for compute in ComputeTarget.list(ws):\n",
    "    if type(compute) is ComputeInstance:\n",
    "        print(compute.name, compute.get_status())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ressources\n",
    "\n",
    "[api azure](https://docs.microsoft.com/en-us/python/api/azureml-core)\n",
    "\n",
    "[parcours d'apprentissage microsoft](https://docs.microsoft.com/fr-fr/learn/paths/build-ai-solutions-with-azure-ml-service/)\n",
    "\n",
    "[le repository microsoft](https://github.com/MicrosoftDocs/mslearn-aml-labs.git)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "256px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}